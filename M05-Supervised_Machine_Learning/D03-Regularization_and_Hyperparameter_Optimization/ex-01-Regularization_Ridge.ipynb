{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-TrUvmyK-GpM"
   },
   "source": [
    "# Regularized linear regression : RIDGE ðŸ‘®ðŸ‘®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GhO_GXwS-XDS"
   },
   "source": [
    "0. Import usual librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "nmzm6Lsf-ZvO",
    "outputId": "060b4a68-5df6-4cef-aba1-a3aedbb91e91"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Force to display all columns in the notebook\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import  OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "# setting Jedha color palette as default\n",
    "pio.templates[\"jedha\"] = go.layout.Template(\n",
    "    layout_colorway=[\"#4B9AC7\", \"#4BE8E0\", \"#9DD4F3\", \"#97FBF6\", \"#2A7FAF\", \"#23B1AB\", \"#0E3449\", \"#015955\"]\n",
    ")\n",
    "pio.templates.default = \"jedha\"\n",
    "pio.renderers.default = \"iframe_connected\" # to be replaced by \"iframe\" if working on JULIE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t-4QtpM5-LW4"
   },
   "source": [
    "1. Load the Online news dataset from the src folder, and use this command to clean out column names :\n",
    "```python\n",
    "data.columns = [name.strip() for name in data.columns]\n",
    "```\n",
    "\n",
    "The description of this dataset is contained in the .txt file present in the same folder.\n",
    "\n",
    "Use the following command to extract a 1000 observations sample:\n",
    "```python\n",
    "data = data.sample(1000, random_state = 0)\n",
    "```\n",
    "\n",
    "Take a moment to display data info in order to check for missing values. \n",
    "We won't use the \"url\" column : you have to drop it.\n",
    "Also just from the variables names we can anticipate that a number of variables will be collinear, remove those variables. Remove also \"LDA_00\", \"rate_positive_words\", \"n_non_stop_words\", that are also near collinear when given a small sample of data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "iBuo8tZ0-BsL",
    "outputId": "849fc24d-0b32-4a2f-8b3b-49d0fec6054d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>data_channel_is_lifestyle</th>\n",
       "      <th>data_channel_is_entertainment</th>\n",
       "      <th>data_channel_is_bus</th>\n",
       "      <th>data_channel_is_socmed</th>\n",
       "      <th>data_channel_is_tech</th>\n",
       "      <th>data_channel_is_world</th>\n",
       "      <th>kw_min_min</th>\n",
       "      <th>kw_max_min</th>\n",
       "      <th>kw_avg_min</th>\n",
       "      <th>kw_min_max</th>\n",
       "      <th>kw_max_max</th>\n",
       "      <th>kw_avg_max</th>\n",
       "      <th>kw_min_avg</th>\n",
       "      <th>kw_max_avg</th>\n",
       "      <th>kw_avg_avg</th>\n",
       "      <th>self_reference_min_shares</th>\n",
       "      <th>self_reference_max_shares</th>\n",
       "      <th>self_reference_avg_sharess</th>\n",
       "      <th>weekday_is_monday</th>\n",
       "      <th>weekday_is_tuesday</th>\n",
       "      <th>weekday_is_wednesday</th>\n",
       "      <th>weekday_is_thursday</th>\n",
       "      <th>weekday_is_friday</th>\n",
       "      <th>weekday_is_saturday</th>\n",
       "      <th>weekday_is_sunday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>LDA_00</th>\n",
       "      <th>LDA_01</th>\n",
       "      <th>LDA_02</th>\n",
       "      <th>LDA_03</th>\n",
       "      <th>LDA_04</th>\n",
       "      <th>global_subjectivity</th>\n",
       "      <th>global_sentiment_polarity</th>\n",
       "      <th>global_rate_positive_words</th>\n",
       "      <th>global_rate_negative_words</th>\n",
       "      <th>rate_positive_words</th>\n",
       "      <th>rate_negative_words</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18765</th>\n",
       "      <td>http://mashable.com/2014/01/13/nokia-first-and...</td>\n",
       "      <td>360.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>810.0</td>\n",
       "      <td>0.455696</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.623950</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.943210</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>746.0</td>\n",
       "      <td>142.285714</td>\n",
       "      <td>12400.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>241971.428571</td>\n",
       "      <td>1366.397260</td>\n",
       "      <td>3535.055510</td>\n",
       "      <td>2336.220331</td>\n",
       "      <td>488.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>2247.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.743268</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.171017</td>\n",
       "      <td>0.511575</td>\n",
       "      <td>0.072003</td>\n",
       "      <td>0.019753</td>\n",
       "      <td>0.014815</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.355966</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.194444</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16349</th>\n",
       "      <td>http://mashable.com/2013/11/19/slow-motion-wed...</td>\n",
       "      <td>415.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.557377</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>211.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>189985.714286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3396.488751</td>\n",
       "      <td>2510.601498</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>4300.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028908</td>\n",
       "      <td>0.028576</td>\n",
       "      <td>0.028606</td>\n",
       "      <td>0.028576</td>\n",
       "      <td>0.885334</td>\n",
       "      <td>0.451923</td>\n",
       "      <td>0.069231</td>\n",
       "      <td>0.024590</td>\n",
       "      <td>0.040984</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.220000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27703</th>\n",
       "      <td>http://mashable.com/2014/06/25/conan-obrien-wo...</td>\n",
       "      <td>197.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>0.391455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.483649</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.712682</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>58.857143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>398911.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3799.224242</td>\n",
       "      <td>2395.346813</td>\n",
       "      <td>3700.0</td>\n",
       "      <td>3700.0</td>\n",
       "      <td>3700.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022289</td>\n",
       "      <td>0.133647</td>\n",
       "      <td>0.022253</td>\n",
       "      <td>0.022224</td>\n",
       "      <td>0.799587</td>\n",
       "      <td>0.422562</td>\n",
       "      <td>0.219951</td>\n",
       "      <td>0.038159</td>\n",
       "      <td>0.005612</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.328018</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.108333</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>11700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32947</th>\n",
       "      <td>http://mashable.com/2014/09/17/ios-8-without-d...</td>\n",
       "      <td>113.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1323.0</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.530740</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.561602</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>810.0</td>\n",
       "      <td>158.571429</td>\n",
       "      <td>12900.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>418728.571429</td>\n",
       "      <td>2486.579592</td>\n",
       "      <td>3481.800852</td>\n",
       "      <td>2931.054867</td>\n",
       "      <td>810.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>11356.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028615</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.028585</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.885657</td>\n",
       "      <td>0.393692</td>\n",
       "      <td>0.149161</td>\n",
       "      <td>0.037793</td>\n",
       "      <td>0.015117</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.359793</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.144266</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35434</th>\n",
       "      <td>http://mashable.com/2014/10/24/ebikes-commute-...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>0.596154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.721212</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.601533</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>529.0</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>42300.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>607440.000000</td>\n",
       "      <td>2494.426728</td>\n",
       "      <td>5880.397106</td>\n",
       "      <td>4186.229243</td>\n",
       "      <td>823.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1011.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.043388</td>\n",
       "      <td>0.040750</td>\n",
       "      <td>0.435827</td>\n",
       "      <td>0.440031</td>\n",
       "      <td>0.040003</td>\n",
       "      <td>0.278509</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.330556</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.198611</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.344444</td>\n",
       "      <td>-0.227778</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.227778</td>\n",
       "      <td>5800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url  timedelta  \\\n",
       "18765  http://mashable.com/2014/01/13/nokia-first-and...      360.0   \n",
       "16349  http://mashable.com/2013/11/19/slow-motion-wed...      415.0   \n",
       "27703  http://mashable.com/2014/06/25/conan-obrien-wo...      197.0   \n",
       "32947  http://mashable.com/2014/09/17/ios-8-without-d...      113.0   \n",
       "35434  http://mashable.com/2014/10/24/ebikes-commute-...       75.0   \n",
       "\n",
       "       n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
       "18765             8.0             810.0         0.455696               1.0   \n",
       "16349            12.0             122.0         0.678571               1.0   \n",
       "27703            12.0             891.0         0.391455               1.0   \n",
       "32947             9.0            1323.0         0.380952               1.0   \n",
       "35434             8.0             261.0         0.596154               1.0   \n",
       "\n",
       "       n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs  \\\n",
       "18765                  0.623950       16.0             7.0       1.0   \n",
       "16349                  0.783333        7.0             2.0       1.0   \n",
       "27703                  0.483649        6.0             3.0      22.0   \n",
       "32947                  0.530740       31.0            11.0      13.0   \n",
       "35434                  0.721212        8.0             3.0       4.0   \n",
       "\n",
       "       num_videos  average_token_length  num_keywords  \\\n",
       "18765         0.0              4.943210           7.0   \n",
       "16349         0.0              4.557377           7.0   \n",
       "27703         2.0              4.712682           9.0   \n",
       "32947         0.0              4.561602           7.0   \n",
       "35434         0.0              4.601533           5.0   \n",
       "\n",
       "       data_channel_is_lifestyle  data_channel_is_entertainment  \\\n",
       "18765                        0.0                            0.0   \n",
       "16349                        0.0                            0.0   \n",
       "27703                        0.0                            0.0   \n",
       "32947                        0.0                            0.0   \n",
       "35434                        0.0                            0.0   \n",
       "\n",
       "       data_channel_is_bus  data_channel_is_socmed  data_channel_is_tech  \\\n",
       "18765                  0.0                     0.0                   0.0   \n",
       "16349                  0.0                     0.0                   1.0   \n",
       "27703                  0.0                     0.0                   1.0   \n",
       "32947                  0.0                     0.0                   1.0   \n",
       "35434                  0.0                     0.0                   0.0   \n",
       "\n",
       "       data_channel_is_world  kw_min_min  kw_max_min  kw_avg_min  kw_min_max  \\\n",
       "18765                    1.0        -1.0       746.0  142.285714     12400.0   \n",
       "16349                    0.0         4.0       633.0  211.500000         0.0   \n",
       "27703                    0.0        -1.0       164.0   58.857143         0.0   \n",
       "32947                    0.0        -1.0       810.0  158.571429     12900.0   \n",
       "35434                    0.0        -1.0       529.0  115.000000     42300.0   \n",
       "\n",
       "       kw_max_max     kw_avg_max   kw_min_avg   kw_max_avg   kw_avg_avg  \\\n",
       "18765    843300.0  241971.428571  1366.397260  3535.055510  2336.220331   \n",
       "16349    843300.0  189985.714286     0.000000  3396.488751  2510.601498   \n",
       "27703    843300.0  398911.111111     0.000000  3799.224242  2395.346813   \n",
       "32947    843300.0  418728.571429  2486.579592  3481.800852  2931.054867   \n",
       "35434    843300.0  607440.000000  2494.426728  5880.397106  4186.229243   \n",
       "\n",
       "       self_reference_min_shares  self_reference_max_shares  \\\n",
       "18765                      488.0                     4500.0   \n",
       "16349                     4300.0                     4300.0   \n",
       "27703                     3700.0                     3700.0   \n",
       "32947                      810.0                    48000.0   \n",
       "35434                      823.0                     1200.0   \n",
       "\n",
       "       self_reference_avg_sharess  weekday_is_monday  weekday_is_tuesday  \\\n",
       "18765                 2247.000000                1.0                 0.0   \n",
       "16349                 4300.000000                0.0                 1.0   \n",
       "27703                 3700.000000                0.0                 0.0   \n",
       "32947                11356.666667                0.0                 0.0   \n",
       "35434                 1011.500000                0.0                 0.0   \n",
       "\n",
       "       weekday_is_wednesday  weekday_is_thursday  weekday_is_friday  \\\n",
       "18765                   0.0                  0.0                0.0   \n",
       "16349                   0.0                  0.0                0.0   \n",
       "27703                   1.0                  0.0                0.0   \n",
       "32947                   1.0                  0.0                0.0   \n",
       "35434                   0.0                  0.0                0.0   \n",
       "\n",
       "       weekday_is_saturday  weekday_is_sunday  is_weekend    LDA_00    LDA_01  \\\n",
       "18765                  0.0                0.0         0.0  0.028572  0.028572   \n",
       "16349                  0.0                0.0         0.0  0.028908  0.028576   \n",
       "27703                  0.0                0.0         0.0  0.022289  0.133647   \n",
       "32947                  0.0                0.0         0.0  0.028615  0.028572   \n",
       "35434                  1.0                0.0         1.0  0.043388  0.040750   \n",
       "\n",
       "         LDA_02    LDA_03    LDA_04  global_subjectivity  \\\n",
       "18765  0.743268  0.028572  0.171017             0.511575   \n",
       "16349  0.028606  0.028576  0.885334             0.451923   \n",
       "27703  0.022253  0.022224  0.799587             0.422562   \n",
       "32947  0.028585  0.028572  0.885657             0.393692   \n",
       "35434  0.435827  0.440031  0.040003             0.278509   \n",
       "\n",
       "       global_sentiment_polarity  global_rate_positive_words  \\\n",
       "18765                   0.072003                    0.019753   \n",
       "16349                   0.069231                    0.024590   \n",
       "27703                   0.219951                    0.038159   \n",
       "32947                   0.149161                    0.037793   \n",
       "35434                   0.041667                    0.022989   \n",
       "\n",
       "       global_rate_negative_words  rate_positive_words  rate_negative_words  \\\n",
       "18765                    0.014815             0.571429             0.428571   \n",
       "16349                    0.040984             0.375000             0.625000   \n",
       "27703                    0.005612             0.871795             0.128205   \n",
       "32947                    0.015117             0.714286             0.285714   \n",
       "35434                    0.022989             0.500000             0.500000   \n",
       "\n",
       "       avg_positive_polarity  min_positive_polarity  max_positive_polarity  \\\n",
       "18765               0.355966               0.100000                    0.6   \n",
       "16349               0.666667               0.500000                    1.0   \n",
       "27703               0.328018               0.100000                    1.0   \n",
       "32947               0.359793               0.062500                    0.8   \n",
       "35434               0.330556               0.033333                    1.0   \n",
       "\n",
       "       avg_negative_polarity  min_negative_polarity  max_negative_polarity  \\\n",
       "18765              -0.194444              -0.600000                 -0.050   \n",
       "16349              -0.220000              -0.500000                 -0.150   \n",
       "27703              -0.108333              -0.166667                 -0.050   \n",
       "32947              -0.144266              -0.500000                 -0.050   \n",
       "35434              -0.198611              -0.300000                 -0.125   \n",
       "\n",
       "       title_subjectivity  title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "18765            0.000000                  0.000000                0.500000   \n",
       "16349            0.433333                  0.066667                0.066667   \n",
       "27703            1.000000                 -0.250000                0.500000   \n",
       "32947            0.000000                  0.000000                0.500000   \n",
       "35434            0.344444                 -0.227778                0.155556   \n",
       "\n",
       "       abs_title_sentiment_polarity  shares  \n",
       "18765                      0.000000     919  \n",
       "16349                      0.066667    1600  \n",
       "27703                      0.250000   11700  \n",
       "32947                      0.000000   18000  \n",
       "35434                      0.227778    5800  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"s3://full-stack-bigdata-datasets/Machine Learning SupervisÃ©/RÃ©gression rÃ©gularisÃ©es/news/OnlineNewsPopularity.csv\")\n",
    "data.columns = [name.strip() for name in data.columns]\n",
    "data = data.sample(1000, random_state = 0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 18765 to 937\n",
      "Data columns (total 61 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   url                            1000 non-null   object \n",
      " 1   timedelta                      1000 non-null   float64\n",
      " 2   n_tokens_title                 1000 non-null   float64\n",
      " 3   n_tokens_content               1000 non-null   float64\n",
      " 4   n_unique_tokens                1000 non-null   float64\n",
      " 5   n_non_stop_words               1000 non-null   float64\n",
      " 6   n_non_stop_unique_tokens       1000 non-null   float64\n",
      " 7   num_hrefs                      1000 non-null   float64\n",
      " 8   num_self_hrefs                 1000 non-null   float64\n",
      " 9   num_imgs                       1000 non-null   float64\n",
      " 10  num_videos                     1000 non-null   float64\n",
      " 11  average_token_length           1000 non-null   float64\n",
      " 12  num_keywords                   1000 non-null   float64\n",
      " 13  data_channel_is_lifestyle      1000 non-null   float64\n",
      " 14  data_channel_is_entertainment  1000 non-null   float64\n",
      " 15  data_channel_is_bus            1000 non-null   float64\n",
      " 16  data_channel_is_socmed         1000 non-null   float64\n",
      " 17  data_channel_is_tech           1000 non-null   float64\n",
      " 18  data_channel_is_world          1000 non-null   float64\n",
      " 19  kw_min_min                     1000 non-null   float64\n",
      " 20  kw_max_min                     1000 non-null   float64\n",
      " 21  kw_avg_min                     1000 non-null   float64\n",
      " 22  kw_min_max                     1000 non-null   float64\n",
      " 23  kw_max_max                     1000 non-null   float64\n",
      " 24  kw_avg_max                     1000 non-null   float64\n",
      " 25  kw_min_avg                     1000 non-null   float64\n",
      " 26  kw_max_avg                     1000 non-null   float64\n",
      " 27  kw_avg_avg                     1000 non-null   float64\n",
      " 28  self_reference_min_shares      1000 non-null   float64\n",
      " 29  self_reference_max_shares      1000 non-null   float64\n",
      " 30  self_reference_avg_sharess     1000 non-null   float64\n",
      " 31  weekday_is_monday              1000 non-null   float64\n",
      " 32  weekday_is_tuesday             1000 non-null   float64\n",
      " 33  weekday_is_wednesday           1000 non-null   float64\n",
      " 34  weekday_is_thursday            1000 non-null   float64\n",
      " 35  weekday_is_friday              1000 non-null   float64\n",
      " 36  weekday_is_saturday            1000 non-null   float64\n",
      " 37  weekday_is_sunday              1000 non-null   float64\n",
      " 38  is_weekend                     1000 non-null   float64\n",
      " 39  LDA_00                         1000 non-null   float64\n",
      " 40  LDA_01                         1000 non-null   float64\n",
      " 41  LDA_02                         1000 non-null   float64\n",
      " 42  LDA_03                         1000 non-null   float64\n",
      " 43  LDA_04                         1000 non-null   float64\n",
      " 44  global_subjectivity            1000 non-null   float64\n",
      " 45  global_sentiment_polarity      1000 non-null   float64\n",
      " 46  global_rate_positive_words     1000 non-null   float64\n",
      " 47  global_rate_negative_words     1000 non-null   float64\n",
      " 48  rate_positive_words            1000 non-null   float64\n",
      " 49  rate_negative_words            1000 non-null   float64\n",
      " 50  avg_positive_polarity          1000 non-null   float64\n",
      " 51  min_positive_polarity          1000 non-null   float64\n",
      " 52  max_positive_polarity          1000 non-null   float64\n",
      " 53  avg_negative_polarity          1000 non-null   float64\n",
      " 54  min_negative_polarity          1000 non-null   float64\n",
      " 55  max_negative_polarity          1000 non-null   float64\n",
      " 56  title_subjectivity             1000 non-null   float64\n",
      " 57  title_sentiment_polarity       1000 non-null   float64\n",
      " 58  abs_title_subjectivity         1000 non-null   float64\n",
      " 59  abs_title_sentiment_polarity   1000 non-null   float64\n",
      " 60  shares                         1000 non-null   int64  \n",
      "dtypes: float64(59), int64(1), object(1)\n",
      "memory usage: 484.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values in this dataset ðŸ˜ŒðŸ˜Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_keep = [col for col in data.columns if col not in [\"url\", \"weekday_is_sunday\",\"is_weekend\", \"LDA_00\", \"rate_positive_words\", \"n_non_stop_words\"]]\n",
    "data = data.loc[:,variables_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1bis. Display a graph with the distribution of the variable shares, what can you conclude from this graph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_15.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.histogram(x = data['shares'], nbins = 120, title = \"Distribution of target variable\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_7.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.histogram(x = data['shares'], nbins = 120, log_y = True, title = 'Distribution of target variable (logarithmic scale)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph of the target variable's distribution indicates that the disribution is extremely skewed, very few very high values are present which would cause our data to be extremely hard to model. Therefore we need to exclude from the dataset the rows where Y takes extremely high values. In this type of situation it is common to convert the target variable to a logarithmic scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "whqaTzyw-lpr"
   },
   "source": [
    "2. Create a dataframe containing the explanatory variables and another one containing only the target variable, which is the number of shares. Convert y to logarithmic scale using np.log10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "zoFLJeNK-gxL",
    "outputId": "fc9909c6-988a-40e5-dd8f-1c0a7547a03e"
   },
   "outputs": [],
   "source": [
    "y = data.iloc[:,-1]\n",
    "y = np.log10(y)\n",
    "X = data.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18765    2.963316\n",
       "16349    3.204120\n",
       "27703    4.068186\n",
       "32947    4.255273\n",
       "35434    3.763428\n",
       "Name: shares, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_10.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.histogram(x = y, nbins = 120, title = \"Distribution of target variable\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>data_channel_is_lifestyle</th>\n",
       "      <th>data_channel_is_entertainment</th>\n",
       "      <th>data_channel_is_bus</th>\n",
       "      <th>data_channel_is_socmed</th>\n",
       "      <th>data_channel_is_tech</th>\n",
       "      <th>data_channel_is_world</th>\n",
       "      <th>kw_min_min</th>\n",
       "      <th>kw_max_min</th>\n",
       "      <th>kw_avg_min</th>\n",
       "      <th>kw_min_max</th>\n",
       "      <th>kw_max_max</th>\n",
       "      <th>kw_avg_max</th>\n",
       "      <th>kw_min_avg</th>\n",
       "      <th>kw_max_avg</th>\n",
       "      <th>kw_avg_avg</th>\n",
       "      <th>self_reference_min_shares</th>\n",
       "      <th>self_reference_max_shares</th>\n",
       "      <th>self_reference_avg_sharess</th>\n",
       "      <th>weekday_is_monday</th>\n",
       "      <th>weekday_is_tuesday</th>\n",
       "      <th>weekday_is_wednesday</th>\n",
       "      <th>weekday_is_thursday</th>\n",
       "      <th>weekday_is_friday</th>\n",
       "      <th>weekday_is_saturday</th>\n",
       "      <th>LDA_01</th>\n",
       "      <th>LDA_02</th>\n",
       "      <th>LDA_03</th>\n",
       "      <th>LDA_04</th>\n",
       "      <th>global_subjectivity</th>\n",
       "      <th>global_sentiment_polarity</th>\n",
       "      <th>global_rate_positive_words</th>\n",
       "      <th>global_rate_negative_words</th>\n",
       "      <th>rate_negative_words</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18765</th>\n",
       "      <td>360.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>810.0</td>\n",
       "      <td>0.455696</td>\n",
       "      <td>0.623950</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.943210</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>746.0</td>\n",
       "      <td>142.285714</td>\n",
       "      <td>12400.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>241971.428571</td>\n",
       "      <td>1366.397260</td>\n",
       "      <td>3535.055510</td>\n",
       "      <td>2336.220331</td>\n",
       "      <td>488.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>2247.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.743268</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.171017</td>\n",
       "      <td>0.511575</td>\n",
       "      <td>0.072003</td>\n",
       "      <td>0.019753</td>\n",
       "      <td>0.014815</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.355966</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.194444</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16349</th>\n",
       "      <td>415.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.557377</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>211.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>189985.714286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3396.488751</td>\n",
       "      <td>2510.601498</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>4300.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028576</td>\n",
       "      <td>0.028606</td>\n",
       "      <td>0.028576</td>\n",
       "      <td>0.885334</td>\n",
       "      <td>0.451923</td>\n",
       "      <td>0.069231</td>\n",
       "      <td>0.024590</td>\n",
       "      <td>0.040984</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.220000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27703</th>\n",
       "      <td>197.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>0.391455</td>\n",
       "      <td>0.483649</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.712682</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>58.857143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>398911.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3799.224242</td>\n",
       "      <td>2395.346813</td>\n",
       "      <td>3700.0</td>\n",
       "      <td>3700.0</td>\n",
       "      <td>3700.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133647</td>\n",
       "      <td>0.022253</td>\n",
       "      <td>0.022224</td>\n",
       "      <td>0.799587</td>\n",
       "      <td>0.422562</td>\n",
       "      <td>0.219951</td>\n",
       "      <td>0.038159</td>\n",
       "      <td>0.005612</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.328018</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.108333</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32947</th>\n",
       "      <td>113.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1323.0</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.530740</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.561602</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>810.0</td>\n",
       "      <td>158.571429</td>\n",
       "      <td>12900.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>418728.571429</td>\n",
       "      <td>2486.579592</td>\n",
       "      <td>3481.800852</td>\n",
       "      <td>2931.054867</td>\n",
       "      <td>810.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>11356.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.028585</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.885657</td>\n",
       "      <td>0.393692</td>\n",
       "      <td>0.149161</td>\n",
       "      <td>0.037793</td>\n",
       "      <td>0.015117</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.359793</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.144266</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35434</th>\n",
       "      <td>75.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>0.596154</td>\n",
       "      <td>0.721212</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.601533</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>529.0</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>42300.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>607440.000000</td>\n",
       "      <td>2494.426728</td>\n",
       "      <td>5880.397106</td>\n",
       "      <td>4186.229243</td>\n",
       "      <td>823.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1011.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.040750</td>\n",
       "      <td>0.435827</td>\n",
       "      <td>0.440031</td>\n",
       "      <td>0.040003</td>\n",
       "      <td>0.278509</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.330556</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.198611</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.344444</td>\n",
       "      <td>-0.227778</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.227778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timedelta  n_tokens_title  n_tokens_content  n_unique_tokens  \\\n",
       "18765      360.0             8.0             810.0         0.455696   \n",
       "16349      415.0            12.0             122.0         0.678571   \n",
       "27703      197.0            12.0             891.0         0.391455   \n",
       "32947      113.0             9.0            1323.0         0.380952   \n",
       "35434       75.0             8.0             261.0         0.596154   \n",
       "\n",
       "       n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs  \\\n",
       "18765                  0.623950       16.0             7.0       1.0   \n",
       "16349                  0.783333        7.0             2.0       1.0   \n",
       "27703                  0.483649        6.0             3.0      22.0   \n",
       "32947                  0.530740       31.0            11.0      13.0   \n",
       "35434                  0.721212        8.0             3.0       4.0   \n",
       "\n",
       "       num_videos  average_token_length  num_keywords  \\\n",
       "18765         0.0              4.943210           7.0   \n",
       "16349         0.0              4.557377           7.0   \n",
       "27703         2.0              4.712682           9.0   \n",
       "32947         0.0              4.561602           7.0   \n",
       "35434         0.0              4.601533           5.0   \n",
       "\n",
       "       data_channel_is_lifestyle  data_channel_is_entertainment  \\\n",
       "18765                        0.0                            0.0   \n",
       "16349                        0.0                            0.0   \n",
       "27703                        0.0                            0.0   \n",
       "32947                        0.0                            0.0   \n",
       "35434                        0.0                            0.0   \n",
       "\n",
       "       data_channel_is_bus  data_channel_is_socmed  data_channel_is_tech  \\\n",
       "18765                  0.0                     0.0                   0.0   \n",
       "16349                  0.0                     0.0                   1.0   \n",
       "27703                  0.0                     0.0                   1.0   \n",
       "32947                  0.0                     0.0                   1.0   \n",
       "35434                  0.0                     0.0                   0.0   \n",
       "\n",
       "       data_channel_is_world  kw_min_min  kw_max_min  kw_avg_min  kw_min_max  \\\n",
       "18765                    1.0        -1.0       746.0  142.285714     12400.0   \n",
       "16349                    0.0         4.0       633.0  211.500000         0.0   \n",
       "27703                    0.0        -1.0       164.0   58.857143         0.0   \n",
       "32947                    0.0        -1.0       810.0  158.571429     12900.0   \n",
       "35434                    0.0        -1.0       529.0  115.000000     42300.0   \n",
       "\n",
       "       kw_max_max     kw_avg_max   kw_min_avg   kw_max_avg   kw_avg_avg  \\\n",
       "18765    843300.0  241971.428571  1366.397260  3535.055510  2336.220331   \n",
       "16349    843300.0  189985.714286     0.000000  3396.488751  2510.601498   \n",
       "27703    843300.0  398911.111111     0.000000  3799.224242  2395.346813   \n",
       "32947    843300.0  418728.571429  2486.579592  3481.800852  2931.054867   \n",
       "35434    843300.0  607440.000000  2494.426728  5880.397106  4186.229243   \n",
       "\n",
       "       self_reference_min_shares  self_reference_max_shares  \\\n",
       "18765                      488.0                     4500.0   \n",
       "16349                     4300.0                     4300.0   \n",
       "27703                     3700.0                     3700.0   \n",
       "32947                      810.0                    48000.0   \n",
       "35434                      823.0                     1200.0   \n",
       "\n",
       "       self_reference_avg_sharess  weekday_is_monday  weekday_is_tuesday  \\\n",
       "18765                 2247.000000                1.0                 0.0   \n",
       "16349                 4300.000000                0.0                 1.0   \n",
       "27703                 3700.000000                0.0                 0.0   \n",
       "32947                11356.666667                0.0                 0.0   \n",
       "35434                 1011.500000                0.0                 0.0   \n",
       "\n",
       "       weekday_is_wednesday  weekday_is_thursday  weekday_is_friday  \\\n",
       "18765                   0.0                  0.0                0.0   \n",
       "16349                   0.0                  0.0                0.0   \n",
       "27703                   1.0                  0.0                0.0   \n",
       "32947                   1.0                  0.0                0.0   \n",
       "35434                   0.0                  0.0                0.0   \n",
       "\n",
       "       weekday_is_saturday    LDA_01    LDA_02    LDA_03    LDA_04  \\\n",
       "18765                  0.0  0.028572  0.743268  0.028572  0.171017   \n",
       "16349                  0.0  0.028576  0.028606  0.028576  0.885334   \n",
       "27703                  0.0  0.133647  0.022253  0.022224  0.799587   \n",
       "32947                  0.0  0.028572  0.028585  0.028572  0.885657   \n",
       "35434                  1.0  0.040750  0.435827  0.440031  0.040003   \n",
       "\n",
       "       global_subjectivity  global_sentiment_polarity  \\\n",
       "18765             0.511575                   0.072003   \n",
       "16349             0.451923                   0.069231   \n",
       "27703             0.422562                   0.219951   \n",
       "32947             0.393692                   0.149161   \n",
       "35434             0.278509                   0.041667   \n",
       "\n",
       "       global_rate_positive_words  global_rate_negative_words  \\\n",
       "18765                    0.019753                    0.014815   \n",
       "16349                    0.024590                    0.040984   \n",
       "27703                    0.038159                    0.005612   \n",
       "32947                    0.037793                    0.015117   \n",
       "35434                    0.022989                    0.022989   \n",
       "\n",
       "       rate_negative_words  avg_positive_polarity  min_positive_polarity  \\\n",
       "18765             0.428571               0.355966               0.100000   \n",
       "16349             0.625000               0.666667               0.500000   \n",
       "27703             0.128205               0.328018               0.100000   \n",
       "32947             0.285714               0.359793               0.062500   \n",
       "35434             0.500000               0.330556               0.033333   \n",
       "\n",
       "       max_positive_polarity  avg_negative_polarity  min_negative_polarity  \\\n",
       "18765                    0.6              -0.194444              -0.600000   \n",
       "16349                    1.0              -0.220000              -0.500000   \n",
       "27703                    1.0              -0.108333              -0.166667   \n",
       "32947                    0.8              -0.144266              -0.500000   \n",
       "35434                    1.0              -0.198611              -0.300000   \n",
       "\n",
       "       max_negative_polarity  title_subjectivity  title_sentiment_polarity  \\\n",
       "18765                 -0.050            0.000000                  0.000000   \n",
       "16349                 -0.150            0.433333                  0.066667   \n",
       "27703                 -0.050            1.000000                 -0.250000   \n",
       "32947                 -0.050            0.000000                  0.000000   \n",
       "35434                 -0.125            0.344444                 -0.227778   \n",
       "\n",
       "       abs_title_subjectivity  abs_title_sentiment_polarity  \n",
       "18765                0.500000                      0.000000  \n",
       "16349                0.066667                      0.066667  \n",
       "27703                0.500000                      0.250000  \n",
       "32947                0.500000                      0.000000  \n",
       "35434                0.155556                      0.227778  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2bis. Produce a list giving the indices of all couples of variables that are correlated above 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 4), (4, 3), (18, 19), (19, 18), (26, 28), (28, 26)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = X.corr()\n",
    "high_corr = corr > 0.90\n",
    "high_corr_list = [(i,j) for i in range(corr.shape[0]) for j in range(corr.shape[0]) if i != j and high_corr.iloc[i,j]]\n",
    "high_corr_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2ter. Remove from X all variables that are correlated above 90%. Create an object X_clean that only contains the variables you would like to keep. If the list is empty, proceed as if it were not because we will need it later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_keep = set([couple[0] for couple in high_corr_list])\n",
    "keep = [i for i in range(X.shape[1]) if i not in no_keep]\n",
    "\n",
    "X_clean = X.iloc[:,keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timedelta', 'n_tokens_title', 'n_tokens_content', 'n_unique_tokens',\n",
       "       'num_hrefs', 'num_self_hrefs', 'num_imgs', 'num_videos',\n",
       "       'average_token_length', 'num_keywords', 'data_channel_is_lifestyle',\n",
       "       'data_channel_is_entertainment', 'data_channel_is_bus',\n",
       "       'data_channel_is_socmed', 'data_channel_is_tech',\n",
       "       'data_channel_is_world', 'kw_min_min', 'kw_max_min', 'kw_min_max',\n",
       "       'kw_max_max', 'kw_avg_max', 'kw_min_avg', 'kw_max_avg', 'kw_avg_avg',\n",
       "       'self_reference_min_shares', 'self_reference_max_shares',\n",
       "       'weekday_is_monday', 'weekday_is_tuesday', 'weekday_is_wednesday',\n",
       "       'weekday_is_thursday', 'weekday_is_friday', 'weekday_is_saturday',\n",
       "       'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04', 'global_subjectivity',\n",
       "       'global_sentiment_polarity', 'global_rate_positive_words',\n",
       "       'global_rate_negative_words', 'rate_negative_words',\n",
       "       'avg_positive_polarity', 'min_positive_polarity',\n",
       "       'max_positive_polarity', 'avg_negative_polarity',\n",
       "       'min_negative_polarity', 'max_negative_polarity', 'title_subjectivity',\n",
       "       'title_sentiment_polarity', 'abs_title_subjectivity',\n",
       "       'abs_title_sentiment_polarity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_keep = [c for c in X.columns if c not in no_keep]\n",
    "\n",
    "X_clean = X.loc[:, columns_to_keep]\n",
    "X_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Are the different variables in your dataset on the same scale ? Verify this by using the describe method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>data_channel_is_lifestyle</th>\n",
       "      <th>data_channel_is_entertainment</th>\n",
       "      <th>data_channel_is_bus</th>\n",
       "      <th>data_channel_is_socmed</th>\n",
       "      <th>data_channel_is_tech</th>\n",
       "      <th>data_channel_is_world</th>\n",
       "      <th>kw_min_min</th>\n",
       "      <th>kw_min_max</th>\n",
       "      <th>kw_max_max</th>\n",
       "      <th>kw_avg_max</th>\n",
       "      <th>kw_min_avg</th>\n",
       "      <th>kw_max_avg</th>\n",
       "      <th>kw_avg_avg</th>\n",
       "      <th>self_reference_max_shares</th>\n",
       "      <th>weekday_is_monday</th>\n",
       "      <th>weekday_is_tuesday</th>\n",
       "      <th>weekday_is_wednesday</th>\n",
       "      <th>weekday_is_thursday</th>\n",
       "      <th>weekday_is_friday</th>\n",
       "      <th>weekday_is_saturday</th>\n",
       "      <th>LDA_01</th>\n",
       "      <th>LDA_02</th>\n",
       "      <th>LDA_03</th>\n",
       "      <th>LDA_04</th>\n",
       "      <th>global_subjectivity</th>\n",
       "      <th>global_sentiment_polarity</th>\n",
       "      <th>global_rate_positive_words</th>\n",
       "      <th>global_rate_negative_words</th>\n",
       "      <th>rate_negative_words</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>347.879000</td>\n",
       "      <td>10.450000</td>\n",
       "      <td>544.410000</td>\n",
       "      <td>11.495000</td>\n",
       "      <td>3.330000</td>\n",
       "      <td>4.364000</td>\n",
       "      <td>1.374000</td>\n",
       "      <td>4.566265</td>\n",
       "      <td>7.19000</td>\n",
       "      <td>0.071000</td>\n",
       "      <td>0.155000</td>\n",
       "      <td>0.179000</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.181000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>23.396000</td>\n",
       "      <td>14001.259000</td>\n",
       "      <td>764439.000000</td>\n",
       "      <td>267915.591185</td>\n",
       "      <td>1051.344541</td>\n",
       "      <td>5837.981819</td>\n",
       "      <td>3167.298728</td>\n",
       "      <td>10329.515000</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>0.198000</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.149000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.133513</td>\n",
       "      <td>0.216622</td>\n",
       "      <td>0.210093</td>\n",
       "      <td>0.238889</td>\n",
       "      <td>0.448885</td>\n",
       "      <td>0.118456</td>\n",
       "      <td>0.039912</td>\n",
       "      <td>0.016804</td>\n",
       "      <td>0.289137</td>\n",
       "      <td>0.356020</td>\n",
       "      <td>0.094289</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>-0.263951</td>\n",
       "      <td>-0.534681</td>\n",
       "      <td>-0.107700</td>\n",
       "      <td>0.288709</td>\n",
       "      <td>0.057511</td>\n",
       "      <td>0.339552</td>\n",
       "      <td>0.157284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>213.608869</td>\n",
       "      <td>2.122264</td>\n",
       "      <td>441.576115</td>\n",
       "      <td>12.462315</td>\n",
       "      <td>4.018862</td>\n",
       "      <td>7.560467</td>\n",
       "      <td>4.497594</td>\n",
       "      <td>0.766976</td>\n",
       "      <td>1.92083</td>\n",
       "      <td>0.256953</td>\n",
       "      <td>0.362086</td>\n",
       "      <td>0.383544</td>\n",
       "      <td>0.211745</td>\n",
       "      <td>0.385211</td>\n",
       "      <td>0.414454</td>\n",
       "      <td>66.383642</td>\n",
       "      <td>58446.111617</td>\n",
       "      <td>191381.569447</td>\n",
       "      <td>134936.208217</td>\n",
       "      <td>1114.166303</td>\n",
       "      <td>7022.567331</td>\n",
       "      <td>1620.230431</td>\n",
       "      <td>35368.240283</td>\n",
       "      <td>0.376697</td>\n",
       "      <td>0.398692</td>\n",
       "      <td>0.389301</td>\n",
       "      <td>0.390908</td>\n",
       "      <td>0.356267</td>\n",
       "      <td>0.218054</td>\n",
       "      <td>0.214749</td>\n",
       "      <td>0.278962</td>\n",
       "      <td>0.287863</td>\n",
       "      <td>0.289179</td>\n",
       "      <td>0.110099</td>\n",
       "      <td>0.092484</td>\n",
       "      <td>0.017494</td>\n",
       "      <td>0.010756</td>\n",
       "      <td>0.149337</td>\n",
       "      <td>0.102030</td>\n",
       "      <td>0.069250</td>\n",
       "      <td>0.244911</td>\n",
       "      <td>0.125986</td>\n",
       "      <td>0.292579</td>\n",
       "      <td>0.096243</td>\n",
       "      <td>0.325868</td>\n",
       "      <td>0.266199</td>\n",
       "      <td>0.188327</td>\n",
       "      <td>0.222283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018227</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.018187</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.267949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>161.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.477636</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "      <td>172823.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3566.297886</td>\n",
       "      <td>2422.624166</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025036</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.028587</td>\n",
       "      <td>0.399413</td>\n",
       "      <td>0.060225</td>\n",
       "      <td>0.028442</td>\n",
       "      <td>0.009738</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.306071</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>331.500000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>411.500000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.668207</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "      <td>248185.714286</td>\n",
       "      <td>927.750000</td>\n",
       "      <td>4396.245773</td>\n",
       "      <td>2865.209621</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033344</td>\n",
       "      <td>0.040015</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.458629</td>\n",
       "      <td>0.118323</td>\n",
       "      <td>0.038613</td>\n",
       "      <td>0.015511</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.361991</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-0.258333</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>539.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>748.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.841608</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6625.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "      <td>344100.350000</td>\n",
       "      <td>1966.086364</td>\n",
       "      <td>5935.906533</td>\n",
       "      <td>3601.081724</td>\n",
       "      <td>8200.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.129532</td>\n",
       "      <td>0.334695</td>\n",
       "      <td>0.310754</td>\n",
       "      <td>0.417068</td>\n",
       "      <td>0.511995</td>\n",
       "      <td>0.177887</td>\n",
       "      <td>0.050689</td>\n",
       "      <td>0.021576</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.412490</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.190989</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>731.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4089.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>5.847262</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>217.000000</td>\n",
       "      <td>690400.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "      <td>798220.000000</td>\n",
       "      <td>3609.718376</td>\n",
       "      <td>138700.000000</td>\n",
       "      <td>36023.424516</td>\n",
       "      <td>663600.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.919755</td>\n",
       "      <td>0.919999</td>\n",
       "      <td>0.919767</td>\n",
       "      <td>0.919983</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.475435</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.080645</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         timedelta  n_tokens_title  n_tokens_content    num_hrefs  \\\n",
       "count  1000.000000     1000.000000       1000.000000  1000.000000   \n",
       "mean    347.879000       10.450000        544.410000    11.495000   \n",
       "std     213.608869        2.122264        441.576115    12.462315   \n",
       "min       9.000000        5.000000          0.000000     0.000000   \n",
       "25%     161.000000        9.000000        248.000000     4.000000   \n",
       "50%     331.500000       10.000000        411.500000     8.000000   \n",
       "75%     539.000000       12.000000        748.000000    14.000000   \n",
       "max     731.000000       18.000000       4089.000000   120.000000   \n",
       "\n",
       "       num_self_hrefs     num_imgs   num_videos  average_token_length  \\\n",
       "count     1000.000000  1000.000000  1000.000000           1000.000000   \n",
       "mean         3.330000     4.364000     1.374000              4.566265   \n",
       "std          4.018862     7.560467     4.497594              0.766976   \n",
       "min          0.000000     0.000000     0.000000              0.000000   \n",
       "25%          1.000000     1.000000     0.000000              4.477636   \n",
       "50%          2.000000     1.000000     0.000000              4.668207   \n",
       "75%          4.000000     4.000000     1.000000              4.841608   \n",
       "max         63.000000    70.000000    51.000000              5.847262   \n",
       "\n",
       "       num_keywords  data_channel_is_lifestyle  data_channel_is_entertainment  \\\n",
       "count    1000.00000                1000.000000                    1000.000000   \n",
       "mean        7.19000                   0.071000                       0.155000   \n",
       "std         1.92083                   0.256953                       0.362086   \n",
       "min         3.00000                   0.000000                       0.000000   \n",
       "25%         6.00000                   0.000000                       0.000000   \n",
       "50%         7.00000                   0.000000                       0.000000   \n",
       "75%         9.00000                   0.000000                       0.000000   \n",
       "max        10.00000                   1.000000                       1.000000   \n",
       "\n",
       "       data_channel_is_bus  data_channel_is_socmed  data_channel_is_tech  \\\n",
       "count          1000.000000             1000.000000           1000.000000   \n",
       "mean              0.179000                0.047000              0.181000   \n",
       "std               0.383544                0.211745              0.385211   \n",
       "min               0.000000                0.000000              0.000000   \n",
       "25%               0.000000                0.000000              0.000000   \n",
       "50%               0.000000                0.000000              0.000000   \n",
       "75%               0.000000                0.000000              0.000000   \n",
       "max               1.000000                1.000000              1.000000   \n",
       "\n",
       "       data_channel_is_world   kw_min_min     kw_min_max     kw_max_max  \\\n",
       "count            1000.000000  1000.000000    1000.000000    1000.000000   \n",
       "mean                0.220000    23.396000   14001.259000  764439.000000   \n",
       "std                 0.414454    66.383642   58446.111617  191381.569447   \n",
       "min                 0.000000    -1.000000       0.000000       0.000000   \n",
       "25%                 0.000000    -1.000000       0.000000  843300.000000   \n",
       "50%                 0.000000    -1.000000    1250.000000  843300.000000   \n",
       "75%                 0.000000     4.000000    6625.000000  843300.000000   \n",
       "max                 1.000000   217.000000  690400.000000  843300.000000   \n",
       "\n",
       "          kw_avg_max   kw_min_avg     kw_max_avg    kw_avg_avg  \\\n",
       "count    1000.000000  1000.000000    1000.000000   1000.000000   \n",
       "mean   267915.591185  1051.344541    5837.981819   3167.298728   \n",
       "std    134936.208217  1114.166303    7022.567331   1620.230431   \n",
       "min         0.000000     0.000000       0.000000      0.000000   \n",
       "25%    172823.900000     0.000000    3566.297886   2422.624166   \n",
       "50%    248185.714286   927.750000    4396.245773   2865.209621   \n",
       "75%    344100.350000  1966.086364    5935.906533   3601.081724   \n",
       "max    798220.000000  3609.718376  138700.000000  36023.424516   \n",
       "\n",
       "       self_reference_max_shares  weekday_is_monday  weekday_is_tuesday  \\\n",
       "count                1000.000000        1000.000000         1000.000000   \n",
       "mean                10329.515000           0.171000            0.198000   \n",
       "std                 35368.240283           0.376697            0.398692   \n",
       "min                     0.000000           0.000000            0.000000   \n",
       "25%                  1200.000000           0.000000            0.000000   \n",
       "50%                  3000.000000           0.000000            0.000000   \n",
       "75%                  8200.000000           0.000000            0.000000   \n",
       "max                663600.000000           1.000000            1.000000   \n",
       "\n",
       "       weekday_is_wednesday  weekday_is_thursday  weekday_is_friday  \\\n",
       "count           1000.000000          1000.000000        1000.000000   \n",
       "mean               0.186000             0.188000           0.149000   \n",
       "std                0.389301             0.390908           0.356267   \n",
       "min                0.000000             0.000000           0.000000   \n",
       "25%                0.000000             0.000000           0.000000   \n",
       "50%                0.000000             0.000000           0.000000   \n",
       "75%                0.000000             0.000000           0.000000   \n",
       "max                1.000000             1.000000           1.000000   \n",
       "\n",
       "       weekday_is_saturday       LDA_01       LDA_02       LDA_03  \\\n",
       "count          1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean              0.050000     0.133513     0.216622     0.210093   \n",
       "std               0.218054     0.214749     0.278962     0.287863   \n",
       "min               0.000000     0.018227     0.020000     0.020000   \n",
       "25%               0.000000     0.025036     0.028572     0.028571   \n",
       "50%               0.000000     0.033344     0.040015     0.040000   \n",
       "75%               0.000000     0.129532     0.334695     0.310754   \n",
       "max               1.000000     0.919755     0.919999     0.919767   \n",
       "\n",
       "            LDA_04  global_subjectivity  global_sentiment_polarity  \\\n",
       "count  1000.000000          1000.000000                1000.000000   \n",
       "mean      0.238889             0.448885                   0.118456   \n",
       "std       0.289179             0.110099                   0.092484   \n",
       "min       0.018187             0.000000                  -0.267949   \n",
       "25%       0.028587             0.399413                   0.060225   \n",
       "50%       0.050000             0.458629                   0.118323   \n",
       "75%       0.417068             0.511995                   0.177887   \n",
       "max       0.919983             0.775000                   0.475435   \n",
       "\n",
       "       global_rate_positive_words  global_rate_negative_words  \\\n",
       "count                 1000.000000                 1000.000000   \n",
       "mean                     0.039912                    0.016804   \n",
       "std                      0.017494                    0.010756   \n",
       "min                      0.000000                    0.000000   \n",
       "25%                      0.028442                    0.009738   \n",
       "50%                      0.038613                    0.015511   \n",
       "75%                      0.050689                    0.021576   \n",
       "max                      0.136986                    0.080645   \n",
       "\n",
       "       rate_negative_words  avg_positive_polarity  min_positive_polarity  \\\n",
       "count          1000.000000            1000.000000            1000.000000   \n",
       "mean              0.289137               0.356020               0.094289   \n",
       "std               0.149337               0.102030               0.069250   \n",
       "min               0.000000               0.000000               0.000000   \n",
       "25%               0.192308               0.306071               0.050000   \n",
       "50%               0.285714               0.361991               0.100000   \n",
       "75%               0.379310               0.412490               0.100000   \n",
       "max               1.000000               0.800000               0.600000   \n",
       "\n",
       "       max_positive_polarity  avg_negative_polarity  min_negative_polarity  \\\n",
       "count            1000.000000            1000.000000            1000.000000   \n",
       "mean                0.766214              -0.263951              -0.534681   \n",
       "std                 0.244911               0.125986               0.292579   \n",
       "min                 0.000000              -1.000000              -1.000000   \n",
       "25%                 0.600000              -0.333333              -0.750000   \n",
       "50%                 0.800000              -0.258333              -0.500000   \n",
       "75%                 1.000000              -0.190989              -0.300000   \n",
       "max                 1.000000               0.000000               0.000000   \n",
       "\n",
       "       max_negative_polarity  title_subjectivity  title_sentiment_polarity  \\\n",
       "count            1000.000000         1000.000000               1000.000000   \n",
       "mean               -0.107700            0.288709                  0.057511   \n",
       "std                 0.096243            0.325868                  0.266199   \n",
       "min                -1.000000            0.000000                 -1.000000   \n",
       "25%                -0.125000            0.000000                  0.000000   \n",
       "50%                -0.100000            0.200000                  0.000000   \n",
       "75%                -0.050000            0.500000                  0.136364   \n",
       "max                 0.000000            1.000000                  1.000000   \n",
       "\n",
       "       abs_title_subjectivity  abs_title_sentiment_polarity  \n",
       "count             1000.000000                   1000.000000  \n",
       "mean                 0.339552                      0.157284  \n",
       "std                  0.188327                      0.222283  \n",
       "min                  0.000000                      0.000000  \n",
       "25%                  0.166667                      0.000000  \n",
       "50%                  0.500000                      0.033333  \n",
       "75%                  0.500000                      0.250000  \n",
       "max                  0.500000                      1.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_clean.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lC9PW2vu_h0v"
   },
   "source": [
    "3bis. Use the `train_test_split` command from the `sklearn.model_selection` package to create a training sample containing 70% of the observations and a test sample containing 30% of the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "colab_type": "code",
    "id": "9xdJd9sz_fOX",
    "outputId": "f73c036f-3b2f-4d98-b805-9bcb9dc35bbe"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3ter. Is it important to normalize data before training a penalized model? If yes normalize your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#it is essential to normalize data when using a penalized model because the penalization is based\n",
    "# on the value of the model parameters which directly depends on the scale of variables.\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vPGXur4x_qve"
   },
   "source": [
    "4. Generate a classical linear regression model, a ridge model where alpha is 10 and a ridge model where alpha is 10000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CPCIHapL_mze"
   },
   "outputs": [],
   "source": [
    "linear_regressor = LinearRegression()\n",
    "ridge_regressor_small_alpha = Ridge(alpha = 10)\n",
    "ridge_regressor_large_alpha = Ridge(alpha = 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AEYP5etM_05G"
   },
   "source": [
    "5. Train these models on the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "0IQdvW5b_wUb",
    "outputId": "248f88e6-bff0-489e-a39e-23cc06cee808"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=10000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regressor.fit(X_train, y_train)\n",
    "ridge_regressor_small_alpha.fit(X_train, y_train)\n",
    "ridge_regressor_large_alpha.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rxX35B6j_4iE"
   },
   "source": [
    "6. Generate performance scores for the three models on the learning and validation sample using the .score attribute.\n",
    "What can you conclude from the scores obtained on the training sample ? \n",
    "What can you conclude from the scores obtained on the test sample ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "nhBGIX2vrg5e",
    "outputId": "673b25b0-1269-4d87-831a-0df570e70412",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training: \n",
      "Linear Regression score : 0.20309718532561072\n",
      "Ridge with small Alpha score : 0.20148323455755235\n",
      "Ridge with large Alpha score : 0.03703249451445478\n"
     ]
    }
   ],
   "source": [
    "print(\"Score on training: \")\n",
    "print(\"Linear Regression score : {}\".format(linear_regressor.score(X_train, y_train)))\n",
    "print(\"Ridge with small Alpha score : {}\".format(ridge_regressor_small_alpha.score(X_train, y_train)))\n",
    "print(\"Ridge with large Alpha score : {}\".format(ridge_regressor_large_alpha.score(X_train,y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score produced by sklearn is $R^2$, and we are noticing a decrease in $R^2$ when the penalization parameter alpha increases. This is completely aligned with the theory, the penalization parameter alpha increases the bias of the model, which is the average prediction error of the model, leading to higher Sum of Square Residual and therefore lower $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "SlbgdO2y_2LA",
    "outputId": "3529f552-a700-402b-c3a4-05a5dea5195c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on test: \n",
      "Linear Regression score: -0.2641530446855114\n",
      "Ridge with small Alpha score: -0.1731083700517222\n",
      "Ridge with large Alpha score: 0.009529922078841513\n"
     ]
    }
   ],
   "source": [
    "print(\"Score on test: \")\n",
    "print(\"Linear Regression score: {}\".format(linear_regressor.score(X_test, y_test)))\n",
    "print(\"Ridge with small Alpha score: {}\".format(ridge_regressor_small_alpha.score(X_test, y_test)))\n",
    "print(\"Ridge with large Alpha score: {}\".format(ridge_regressor_large_alpha.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we witness on the scores is very interesting. First, of all the scores obtained are much lower than those obtained on the training sample. Besides, one can notice the following :\n",
    "- $\\alpha = 0 \\implies R^2_{test} << R^2_{train}$ : without any regularization, the model is overfitting\n",
    "- $\\alpha = 10 \\implies R^2_{test} << R^2_{train}$: with a small $\\alpha$, the model is still overfitting\n",
    "- $\\alpha = 10000 \\implies R^2_{test} \\sim R^2_{train}$ but both low: with a high $\\alpha$, the model is underfitting (the score deteriorated on the train set)\n",
    "\n",
    "So it seems that a happy middle ground could exist where a certain value of $\\alpha$ would derive optimal results on our test set, this shows that Ridge can help us find the best compromise between bias and variance for a linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y-FCEvIUASw9"
   },
   "source": [
    "7. Compare the coefficients of the three models using a table, what do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "s9Cw09XrAKOG",
    "outputId": "2747a3e5-a0ae-402d-d894-6ecb319a74d2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coef_linear_regressor</th>\n",
       "      <th>coef_ridge_small_alpha</th>\n",
       "      <th>coef_ridge_large_alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>timedelta</td>\n",
       "      <td>-0.005779</td>\n",
       "      <td>-0.003683</td>\n",
       "      <td>0.000685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n_tokens_title</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.009204</td>\n",
       "      <td>-0.000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n_tokens_content</td>\n",
       "      <td>0.064608</td>\n",
       "      <td>0.052034</td>\n",
       "      <td>0.001789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n_unique_tokens</td>\n",
       "      <td>0.130484</td>\n",
       "      <td>0.081234</td>\n",
       "      <td>-0.001164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n_non_stop_unique_tokens</td>\n",
       "      <td>-0.113480</td>\n",
       "      <td>-0.075011</td>\n",
       "      <td>-0.002259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>num_hrefs</td>\n",
       "      <td>-0.011959</td>\n",
       "      <td>-0.009116</td>\n",
       "      <td>0.002540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>num_self_hrefs</td>\n",
       "      <td>-0.007465</td>\n",
       "      <td>-0.007948</td>\n",
       "      <td>0.000690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>num_imgs</td>\n",
       "      <td>0.030227</td>\n",
       "      <td>0.032087</td>\n",
       "      <td>0.003977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>num_videos</td>\n",
       "      <td>-0.007350</td>\n",
       "      <td>-0.008363</td>\n",
       "      <td>0.000231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>average_token_length</td>\n",
       "      <td>-0.014288</td>\n",
       "      <td>-0.009037</td>\n",
       "      <td>-0.001326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>num_keywords</td>\n",
       "      <td>0.028097</td>\n",
       "      <td>0.029240</td>\n",
       "      <td>0.001583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>data_channel_is_lifestyle</td>\n",
       "      <td>0.013726</td>\n",
       "      <td>0.005698</td>\n",
       "      <td>-0.000091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>data_channel_is_entertainment</td>\n",
       "      <td>-0.006164</td>\n",
       "      <td>-0.015318</td>\n",
       "      <td>-0.002199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>data_channel_is_bus</td>\n",
       "      <td>0.017916</td>\n",
       "      <td>0.007521</td>\n",
       "      <td>-0.000716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>data_channel_is_socmed</td>\n",
       "      <td>0.032036</td>\n",
       "      <td>0.028094</td>\n",
       "      <td>0.002320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>data_channel_is_tech</td>\n",
       "      <td>0.045213</td>\n",
       "      <td>0.031209</td>\n",
       "      <td>-0.000282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>data_channel_is_world</td>\n",
       "      <td>0.080375</td>\n",
       "      <td>0.062142</td>\n",
       "      <td>-0.002082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>kw_min_min</td>\n",
       "      <td>0.037146</td>\n",
       "      <td>0.036208</td>\n",
       "      <td>0.001608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>kw_max_min</td>\n",
       "      <td>-0.035662</td>\n",
       "      <td>-0.024643</td>\n",
       "      <td>0.000324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>kw_avg_min</td>\n",
       "      <td>0.063545</td>\n",
       "      <td>0.048455</td>\n",
       "      <td>0.000595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>kw_min_max</td>\n",
       "      <td>0.022255</td>\n",
       "      <td>0.021561</td>\n",
       "      <td>0.002017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>kw_max_max</td>\n",
       "      <td>0.001643</td>\n",
       "      <td>0.001738</td>\n",
       "      <td>-0.000810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>kw_avg_max</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.007273</td>\n",
       "      <td>0.002175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>kw_min_avg</td>\n",
       "      <td>-0.028412</td>\n",
       "      <td>-0.017705</td>\n",
       "      <td>0.002708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>kw_max_avg</td>\n",
       "      <td>-0.130549</td>\n",
       "      <td>-0.104282</td>\n",
       "      <td>0.001237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>kw_avg_avg</td>\n",
       "      <td>0.162350</td>\n",
       "      <td>0.129600</td>\n",
       "      <td>0.004700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>self_reference_min_shares</td>\n",
       "      <td>0.054402</td>\n",
       "      <td>0.032795</td>\n",
       "      <td>0.002325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>self_reference_max_shares</td>\n",
       "      <td>-0.004227</td>\n",
       "      <td>-0.014578</td>\n",
       "      <td>0.001413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>self_reference_avg_sharess</td>\n",
       "      <td>-0.025037</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.002208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>weekday_is_monday</td>\n",
       "      <td>-0.027280</td>\n",
       "      <td>-0.025094</td>\n",
       "      <td>-0.000718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>weekday_is_tuesday</td>\n",
       "      <td>-0.044045</td>\n",
       "      <td>-0.041076</td>\n",
       "      <td>-0.001855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>weekday_is_wednesday</td>\n",
       "      <td>-0.031351</td>\n",
       "      <td>-0.029622</td>\n",
       "      <td>-0.000640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>weekday_is_thursday</td>\n",
       "      <td>-0.056907</td>\n",
       "      <td>-0.053767</td>\n",
       "      <td>-0.002063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>weekday_is_friday</td>\n",
       "      <td>-0.001981</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>0.001478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>weekday_is_saturday</td>\n",
       "      <td>0.047677</td>\n",
       "      <td>0.048562</td>\n",
       "      <td>0.004375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>LDA_01</td>\n",
       "      <td>-0.023811</td>\n",
       "      <td>-0.021352</td>\n",
       "      <td>-0.002014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>LDA_02</td>\n",
       "      <td>-0.077856</td>\n",
       "      <td>-0.071885</td>\n",
       "      <td>-0.003176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>LDA_03</td>\n",
       "      <td>0.026790</td>\n",
       "      <td>0.031021</td>\n",
       "      <td>0.005254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>LDA_04</td>\n",
       "      <td>-0.058837</td>\n",
       "      <td>-0.052441</td>\n",
       "      <td>-0.001219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>global_subjectivity</td>\n",
       "      <td>0.054573</td>\n",
       "      <td>0.051716</td>\n",
       "      <td>0.002524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>global_sentiment_polarity</td>\n",
       "      <td>-0.047521</td>\n",
       "      <td>-0.044336</td>\n",
       "      <td>0.000975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>global_rate_positive_words</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.001404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>global_rate_negative_words</td>\n",
       "      <td>0.002754</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>rate_negative_words</td>\n",
       "      <td>-0.039561</td>\n",
       "      <td>-0.033318</td>\n",
       "      <td>-0.001087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>avg_positive_polarity</td>\n",
       "      <td>-0.025268</td>\n",
       "      <td>-0.022768</td>\n",
       "      <td>0.000563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>min_positive_polarity</td>\n",
       "      <td>0.010062</td>\n",
       "      <td>0.010281</td>\n",
       "      <td>0.000081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>max_positive_polarity</td>\n",
       "      <td>0.028938</td>\n",
       "      <td>0.024068</td>\n",
       "      <td>0.001053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>avg_negative_polarity</td>\n",
       "      <td>0.045716</td>\n",
       "      <td>0.042539</td>\n",
       "      <td>0.001229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>min_negative_polarity</td>\n",
       "      <td>-0.009408</td>\n",
       "      <td>-0.005623</td>\n",
       "      <td>-0.000245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>max_negative_polarity</td>\n",
       "      <td>0.010071</td>\n",
       "      <td>0.010442</td>\n",
       "      <td>0.001907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>title_subjectivity</td>\n",
       "      <td>0.005210</td>\n",
       "      <td>0.006436</td>\n",
       "      <td>0.001910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>title_sentiment_polarity</td>\n",
       "      <td>0.030728</td>\n",
       "      <td>0.028975</td>\n",
       "      <td>0.001523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>abs_title_subjectivity</td>\n",
       "      <td>0.006739</td>\n",
       "      <td>0.005080</td>\n",
       "      <td>-0.000426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>abs_title_sentiment_polarity</td>\n",
       "      <td>0.009070</td>\n",
       "      <td>0.007258</td>\n",
       "      <td>0.001634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         features  coef_linear_regressor  \\\n",
       "0                       timedelta              -0.005779   \n",
       "1                  n_tokens_title               0.010425   \n",
       "2                n_tokens_content               0.064608   \n",
       "3                 n_unique_tokens               0.130484   \n",
       "4        n_non_stop_unique_tokens              -0.113480   \n",
       "5                       num_hrefs              -0.011959   \n",
       "6                  num_self_hrefs              -0.007465   \n",
       "7                        num_imgs               0.030227   \n",
       "8                      num_videos              -0.007350   \n",
       "9            average_token_length              -0.014288   \n",
       "10                   num_keywords               0.028097   \n",
       "11      data_channel_is_lifestyle               0.013726   \n",
       "12  data_channel_is_entertainment              -0.006164   \n",
       "13            data_channel_is_bus               0.017916   \n",
       "14         data_channel_is_socmed               0.032036   \n",
       "15           data_channel_is_tech               0.045213   \n",
       "16          data_channel_is_world               0.080375   \n",
       "17                     kw_min_min               0.037146   \n",
       "18                     kw_max_min              -0.035662   \n",
       "19                     kw_avg_min               0.063545   \n",
       "20                     kw_min_max               0.022255   \n",
       "21                     kw_max_max               0.001643   \n",
       "22                     kw_avg_max               0.003572   \n",
       "23                     kw_min_avg              -0.028412   \n",
       "24                     kw_max_avg              -0.130549   \n",
       "25                     kw_avg_avg               0.162350   \n",
       "26      self_reference_min_shares               0.054402   \n",
       "27      self_reference_max_shares              -0.004227   \n",
       "28     self_reference_avg_sharess              -0.025037   \n",
       "29              weekday_is_monday              -0.027280   \n",
       "30             weekday_is_tuesday              -0.044045   \n",
       "31           weekday_is_wednesday              -0.031351   \n",
       "32            weekday_is_thursday              -0.056907   \n",
       "33              weekday_is_friday              -0.001981   \n",
       "34            weekday_is_saturday               0.047677   \n",
       "35                         LDA_01              -0.023811   \n",
       "36                         LDA_02              -0.077856   \n",
       "37                         LDA_03               0.026790   \n",
       "38                         LDA_04              -0.058837   \n",
       "39            global_subjectivity               0.054573   \n",
       "40      global_sentiment_polarity              -0.047521   \n",
       "41     global_rate_positive_words               0.000312   \n",
       "42     global_rate_negative_words               0.002754   \n",
       "43            rate_negative_words              -0.039561   \n",
       "44          avg_positive_polarity              -0.025268   \n",
       "45          min_positive_polarity               0.010062   \n",
       "46          max_positive_polarity               0.028938   \n",
       "47          avg_negative_polarity               0.045716   \n",
       "48          min_negative_polarity              -0.009408   \n",
       "49          max_negative_polarity               0.010071   \n",
       "50             title_subjectivity               0.005210   \n",
       "51       title_sentiment_polarity               0.030728   \n",
       "52         abs_title_subjectivity               0.006739   \n",
       "53   abs_title_sentiment_polarity               0.009070   \n",
       "\n",
       "    coef_ridge_small_alpha  coef_ridge_large_alpha  \n",
       "0                -0.003683                0.000685  \n",
       "1                 0.009204               -0.000054  \n",
       "2                 0.052034                0.001789  \n",
       "3                 0.081234               -0.001164  \n",
       "4                -0.075011               -0.002259  \n",
       "5                -0.009116                0.002540  \n",
       "6                -0.007948                0.000690  \n",
       "7                 0.032087                0.003977  \n",
       "8                -0.008363                0.000231  \n",
       "9                -0.009037               -0.001326  \n",
       "10                0.029240                0.001583  \n",
       "11                0.005698               -0.000091  \n",
       "12               -0.015318               -0.002199  \n",
       "13                0.007521               -0.000716  \n",
       "14                0.028094                0.002320  \n",
       "15                0.031209               -0.000282  \n",
       "16                0.062142               -0.002082  \n",
       "17                0.036208                0.001608  \n",
       "18               -0.024643                0.000324  \n",
       "19                0.048455                0.000595  \n",
       "20                0.021561                0.002017  \n",
       "21                0.001738               -0.000810  \n",
       "22                0.007273                0.002175  \n",
       "23               -0.017705                0.002708  \n",
       "24               -0.104282                0.001237  \n",
       "25                0.129600                0.004700  \n",
       "26                0.032795                0.002325  \n",
       "27               -0.014578                0.001413  \n",
       "28                0.005051                0.002208  \n",
       "29               -0.025094               -0.000718  \n",
       "30               -0.041076               -0.001855  \n",
       "31               -0.029622               -0.000640  \n",
       "32               -0.053767               -0.002063  \n",
       "33                0.000840                0.001478  \n",
       "34                0.048562                0.004375  \n",
       "35               -0.021352               -0.002014  \n",
       "36               -0.071885               -0.003176  \n",
       "37                0.031021                0.005254  \n",
       "38               -0.052441               -0.001219  \n",
       "39                0.051716                0.002524  \n",
       "40               -0.044336                0.000975  \n",
       "41                0.005225                0.001404  \n",
       "42                0.000776                0.000070  \n",
       "43               -0.033318               -0.001087  \n",
       "44               -0.022768                0.000563  \n",
       "45                0.010281                0.000081  \n",
       "46                0.024068                0.001053  \n",
       "47                0.042539                0.001229  \n",
       "48               -0.005623               -0.000245  \n",
       "49                0.010442                0.001907  \n",
       "50                0.006436                0.001910  \n",
       "51                0.028975                0.001523  \n",
       "52                0.005080               -0.000426  \n",
       "53                0.007258                0.001634  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef = pd.DataFrame()\n",
    "coef['features'] = X.columns\n",
    "coef['coef_linear_regressor'] = linear_regressor.coef_\n",
    "coef['coef_ridge_small_alpha'] = ridge_regressor_small_alpha.coef_\n",
    "coef['coef_ridge_large_alpha'] = ridge_regressor_large_alpha.coef_\n",
    "coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the higher the value of alpha, the more the coefficients seem to shrink near zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_26.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perf_lin = pd.DataFrame({\"params\": linear_regressor.coef_, \n",
    "                                       \"model\": \"linear_regressor\", \n",
    "                                       \"index\": range(0, len(X.columns))})\n",
    "\n",
    "perf_ridge_large_alpha = pd.DataFrame({\"params\": ridge_regressor_large_alpha.coef_, \n",
    "                                       \"model\": \"ridge Alpha = 100\", \n",
    "                                       \"index\": range(0, len(X.columns))})\n",
    "\n",
    "perf_ridge_small_alpha = pd.DataFrame({\"params\": ridge_regressor_small_alpha.coef_, \n",
    "                                       \"model\": \"ridge Alpha = 0.01\", \n",
    "                                       \"index\": range(0, len(X.columns))})\n",
    "\n",
    "perf_compar = pd.concat([perf_ridge_large_alpha,perf_ridge_small_alpha,perf_lin])\n",
    "\n",
    "px.line(perf_compar, x = 'index', y = 'params', color = 'model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1ty5SIgDAzbw"
   },
   "source": [
    "In the figure, we are able to notice the shrink even more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "orQ4-NbwF4QW"
   },
   "source": [
    "8. Find the optimal value for the hyper-parameter alpha using sklearn function GridSearchCV. Try values from 0 to 1000 with a step of 10, use a value of 10 as the \"cv\" parameter and a value of 1 for the \"verbose\" parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "colab_type": "code",
    "id": "5kjsUd-2AqMw",
    "outputId": "e63e3d25-f209-4987-bf5a-c2625303680e",
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    }
   ],
   "source": [
    "params = {'alpha': np.arange(0,10000,100)} # determine the range of parameters to try\n",
    "ridge = Ridge() # create an instance of the model\n",
    "\n",
    "grid = GridSearchCV(ridge, params, cv = 10, verbose = 1)\n",
    "grid_fit = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-Nb5OEGeEy4Y",
    "outputId": "103c2183-5cdd-4c3c-fca5-38c885b77c83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal value for alpha :  {'alpha': 700}\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal value for alpha : \", grid_fit.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. What is the score on the test set obtained using this optimal alpha parameter ? You might find a score that seems lower to the ones obtained before grid search. Can you explain why ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "l1bcTNJRF08C",
    "outputId": "8ed2f8e3-7374-465d-f025-5a03f83f698f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score for the best model :  0.011984750234474428\n"
     ]
    }
   ],
   "source": [
    "print('Test score for the best model : ', grid_fit.best_estimator_.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validated R2-score is :  0.06550028972850007\n",
      "The standard deviation is :  0.04813737501083121\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(grid_fit.best_estimator_, X_train, y_train, cv = 10)\n",
    "\n",
    "print('The cross-validated R2-score is : ', scores.mean())\n",
    "print('The standard deviation is : ', scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acutally, the score of the best model is not **significantly different** from the previous ones !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. **Bonus question** Try going back to the beginning of the exercise and running it without extracting a small sample of data from the original dataset, do you get the same types of results? What does it tell you about ridge regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When increasing the number of samples in the data, it seems that ridge is not better than the linear regression model anymore, the penalization does not work. What does this tell us ? When using a relatively small sample of data ridge was better than linear regression, meaning linear regression's variance was too high and its bias was too low to derve good results on the test set, therefore the penalized version, ridge, git us better results. This is linked to the fact that a smaller sample of data naturally has lower variance than a bigger sample, therefore a model with lower variance is needed.\n",
    "\n",
    "When increasing the number of sample back to normal, we increase the variance in the data dramatically. This increase in variance within the data calls for a model with higher variance and lower bias, which explains why, when all samples are selected, the results of ridge are not as convincing anymore."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RÃ©gressions RÃ©gularisÃ©es - Ridge Exercice SOLUTION.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
