{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEa8O_OU8RO_"
      },
      "source": [
        "# Embedding for Sentiment Analysis \n",
        "\n",
        "Now that we know how word embedding works, we'll apply it to a supervised problem of sentiment analysis. The idea is to classify the comments left by users according to the number of stars they gave the Disneyland resort park in their reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlZE3Ntm8gv4"
      },
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "### Import Data \n",
        "\n",
        "1. Import the following libraries:\n",
        "\n",
        "* tensorflow \n",
        "* pathlib\n",
        "* pandas \n",
        "* os\n",
        "* io\n",
        "* `sklearn.model_selection.train_test_split`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RMBnbVdZygEr"
      },
      "outputs": [],
      "source": [
        "# Import Tensorflow & Pathlib librairies\n",
        "import tensorflow as tf \n",
        "import pathlib \n",
        "import pandas as pd \n",
        "import os\n",
        "import io\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIiJ3wIKkC_c"
      },
      "source": [
        "2. Copy the link below and read the file it contains with `pandas`.\n",
        "\n",
        "* https://go.aws/314bBDq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "Irik4DyW0acS",
        "outputId": "de9e2a19-203f-40c1-99ef-e4fa34f45edf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>review</th>\n",
              "      <th>stars</th>\n",
              "      <th>date_format</th>\n",
              "      <th>time_of_day</th>\n",
              "      <th>hour_of_day</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>review_format</th>\n",
              "      <th>review_lang</th>\n",
              "      <th>month_year</th>\n",
              "      <th>review_len</th>\n",
              "      <th>review_nb_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>efb62a167fee5cf3678b24427de8e31f</td>\n",
              "      <td>Génial, fabuleux, exceptionnel ! J'aimerais qu...</td>\n",
              "      <td>5</td>\n",
              "      <td>2017-09-29 18:17:00</td>\n",
              "      <td>18:17</td>\n",
              "      <td>18</td>\n",
              "      <td>Ven</td>\n",
              "      <td>génial  fabuleux  exceptionnel   j aimerais qu...</td>\n",
              "      <td>french</td>\n",
              "      <td>2017-09</td>\n",
              "      <td>115</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>e3be4f9c9e0b9572bfb2a5f88497bb14</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>2017-09-29 17:29:00</td>\n",
              "      <td>17:29</td>\n",
              "      <td>17</td>\n",
              "      <td>Ven</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2017-09</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1b8e5760162d867e9b9ca80f645bdc60</td>\n",
              "      <td>Toujours aussi magic, féerique !</td>\n",
              "      <td>5</td>\n",
              "      <td>2017-09-29 16:46:00</td>\n",
              "      <td>16:46</td>\n",
              "      <td>16</td>\n",
              "      <td>Ven</td>\n",
              "      <td>toujours aussi magic  féerique</td>\n",
              "      <td>french</td>\n",
              "      <td>2017-09</td>\n",
              "      <td>32</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>fa330e5891a1bb486c3e9bf95c098726</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>2017-09-29 15:52:00</td>\n",
              "      <td>15:52</td>\n",
              "      <td>15</td>\n",
              "      <td>Ven</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2017-09</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>c1a693206aee1a2412d4bd9e45b80ec5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>2017-09-29 15:29:00</td>\n",
              "      <td>15:29</td>\n",
              "      <td>15</td>\n",
              "      <td>Ven</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2017-09</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            user_id  \\\n",
              "0  efb62a167fee5cf3678b24427de8e31f   \n",
              "1  e3be4f9c9e0b9572bfb2a5f88497bb14   \n",
              "2  1b8e5760162d867e9b9ca80f645bdc60   \n",
              "3  fa330e5891a1bb486c3e9bf95c098726   \n",
              "4  c1a693206aee1a2412d4bd9e45b80ec5   \n",
              "\n",
              "                                              review  stars  \\\n",
              "0  Génial, fabuleux, exceptionnel ! J'aimerais qu...      5   \n",
              "1                                                NaN      2   \n",
              "2                   Toujours aussi magic, féerique !      5   \n",
              "3                                                NaN      5   \n",
              "4                                                NaN      3   \n",
              "\n",
              "           date_format time_of_day  hour_of_day day_of_week  \\\n",
              "0  2017-09-29 18:17:00       18:17           18         Ven   \n",
              "1  2017-09-29 17:29:00       17:29           17         Ven   \n",
              "2  2017-09-29 16:46:00       16:46           16         Ven   \n",
              "3  2017-09-29 15:52:00       15:52           15         Ven   \n",
              "4  2017-09-29 15:29:00       15:29           15         Ven   \n",
              "\n",
              "                                       review_format review_lang month_year  \\\n",
              "0  génial  fabuleux  exceptionnel   j aimerais qu...      french    2017-09   \n",
              "1                                                NaN         NaN    2017-09   \n",
              "2                   toujours aussi magic  féerique        french    2017-09   \n",
              "3                                                NaN         NaN    2017-09   \n",
              "4                                                NaN         NaN    2017-09   \n",
              "\n",
              "   review_len  review_nb_words  \n",
              "0         115               19  \n",
              "1           0                0  \n",
              "2          32                4  \n",
              "3           0                0  \n",
              "4           0                0  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import dataset with Pandas \n",
        "dataset = pd.read_csv(\"https://go.aws/314bBDq\", error_bad_lines=False, encoding=\"utf-8\")\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_SUNZnzldIC"
      },
      "source": [
        "3. We will need the reviews in French. Filter the reviews so that they are in the right language. For this you need to find a column that gives you that information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>review</th>\n",
              "      <th>stars</th>\n",
              "      <th>date_format</th>\n",
              "      <th>time_of_day</th>\n",
              "      <th>hour_of_day</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>review_format</th>\n",
              "      <th>review_lang</th>\n",
              "      <th>month_year</th>\n",
              "      <th>review_len</th>\n",
              "      <th>review_nb_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>efb62a167fee5cf3678b24427de8e31f</td>\n",
              "      <td>Génial, fabuleux, exceptionnel ! J'aimerais qu...</td>\n",
              "      <td>5</td>\n",
              "      <td>2017-09-29 18:17:00</td>\n",
              "      <td>18:17</td>\n",
              "      <td>18</td>\n",
              "      <td>Ven</td>\n",
              "      <td>génial  fabuleux  exceptionnel   j aimerais qu...</td>\n",
              "      <td>french</td>\n",
              "      <td>2017-09</td>\n",
              "      <td>115</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1b8e5760162d867e9b9ca80f645bdc60</td>\n",
              "      <td>Toujours aussi magic, féerique !</td>\n",
              "      <td>5</td>\n",
              "      <td>2017-09-29 16:46:00</td>\n",
              "      <td>16:46</td>\n",
              "      <td>16</td>\n",
              "      <td>Ven</td>\n",
              "      <td>toujours aussi magic  féerique</td>\n",
              "      <td>french</td>\n",
              "      <td>2017-09</td>\n",
              "      <td>32</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>726b1a3e2664e8b075129bcd643dbf56</td>\n",
              "      <td>En vacances en région parisienne nous nous som...</td>\n",
              "      <td>2</td>\n",
              "      <td>2017-09-29 00:37:00</td>\n",
              "      <td>00:37</td>\n",
              "      <td>0</td>\n",
              "      <td>Ven</td>\n",
              "      <td>en vacances en région parisienne nous nous som...</td>\n",
              "      <td>french</td>\n",
              "      <td>2017-09</td>\n",
              "      <td>172</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>8a71763fbb3da7436b957681b24cc404</td>\n",
              "      <td>Tropbeaufinalpleinlesyeuxoreil</td>\n",
              "      <td>5</td>\n",
              "      <td>2017-09-29 00:16:00</td>\n",
              "      <td>00:16</td>\n",
              "      <td>0</td>\n",
              "      <td>Ven</td>\n",
              "      <td>tropbeaufinalpleinlesyeuxoreil</td>\n",
              "      <td>french</td>\n",
              "      <td>2017-09</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>ce7abd7798ee036d667c0ad84b85daa7</td>\n",
              "      <td>L'univers Disney reste merveilleux. Toutefois ...</td>\n",
              "      <td>4</td>\n",
              "      <td>2017-09-28 20:24:00</td>\n",
              "      <td>20:24</td>\n",
              "      <td>20</td>\n",
              "      <td>Jeu</td>\n",
              "      <td>l univers disney reste merveilleux  toutefois ...</td>\n",
              "      <td>french</td>\n",
              "      <td>2017-09</td>\n",
              "      <td>148</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             user_id  \\\n",
              "0   efb62a167fee5cf3678b24427de8e31f   \n",
              "2   1b8e5760162d867e9b9ca80f645bdc60   \n",
              "11  726b1a3e2664e8b075129bcd643dbf56   \n",
              "12  8a71763fbb3da7436b957681b24cc404   \n",
              "23  ce7abd7798ee036d667c0ad84b85daa7   \n",
              "\n",
              "                                               review  stars  \\\n",
              "0   Génial, fabuleux, exceptionnel ! J'aimerais qu...      5   \n",
              "2                    Toujours aussi magic, féerique !      5   \n",
              "11  En vacances en région parisienne nous nous som...      2   \n",
              "12                     Tropbeaufinalpleinlesyeuxoreil      5   \n",
              "23  L'univers Disney reste merveilleux. Toutefois ...      4   \n",
              "\n",
              "            date_format time_of_day  hour_of_day day_of_week  \\\n",
              "0   2017-09-29 18:17:00       18:17           18         Ven   \n",
              "2   2017-09-29 16:46:00       16:46           16         Ven   \n",
              "11  2017-09-29 00:37:00       00:37            0         Ven   \n",
              "12  2017-09-29 00:16:00       00:16            0         Ven   \n",
              "23  2017-09-28 20:24:00       20:24           20         Jeu   \n",
              "\n",
              "                                        review_format review_lang month_year  \\\n",
              "0   génial  fabuleux  exceptionnel   j aimerais qu...      french    2017-09   \n",
              "2                    toujours aussi magic  féerique        french    2017-09   \n",
              "11  en vacances en région parisienne nous nous som...      french    2017-09   \n",
              "12                     tropbeaufinalpleinlesyeuxoreil      french    2017-09   \n",
              "23  l univers disney reste merveilleux  toutefois ...      french    2017-09   \n",
              "\n",
              "    review_len  review_nb_words  \n",
              "0          115               19  \n",
              "2           32                4  \n",
              "11         172               25  \n",
              "12          30                1  \n",
              "23         148               23  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Taking only french reviews\n",
        "french_reviews = dataset[dataset.review_lang == \"french\"]\n",
        "french_reviews.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "As6OupSYl5La"
      },
      "source": [
        "4. Keep only the `review` & `stars` columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xe2j2atl1qNM",
        "outputId": "b71519c2-5944-4130-fffa-1a07dad518d9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>stars</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Génial, fabuleux, exceptionnel ! J'aimerais qu...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Toujours aussi magic, féerique !</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>En vacances en région parisienne nous nous som...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Tropbeaufinalpleinlesyeuxoreil</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>L'univers Disney reste merveilleux. Toutefois ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               review  stars\n",
              "0   Génial, fabuleux, exceptionnel ! J'aimerais qu...      5\n",
              "2                    Toujours aussi magic, féerique !      5\n",
              "11  En vacances en région parisienne nous nous som...      2\n",
              "12                     Tropbeaufinalpleinlesyeuxoreil      5\n",
              "23  L'univers Disney reste merveilleux. Toutefois ...      4"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's take the columns we're interested in \n",
        "french_reviews = french_reviews[[\"review\", \"stars\"]]\n",
        "french_reviews.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8Duro5f8i7U"
      },
      "source": [
        "### Preprocessing\n",
        "\n",
        "We will now go through a preprocessing phase. The goal is to clean up the character strings and encode the words so they are represented as integers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1khjji0HMvk"
      },
      "source": [
        "1. Use the command: `!python -m spacy download fr_core_news_md` to download all language elements related to the French language"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwTE6DhFmH7A",
        "outputId": "6ab54716-e2b3-47fa-c0d6-26b02dc09ef2"
      },
      "outputs": [],
      "source": [
        "# !python -m spacy download fr_core_news_md -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBnV02P_HYHB"
      },
      "source": [
        "2. Load now `fr_core_news_md` into a variable called `nlp`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xhHn4g5VmlPa"
      },
      "outputs": [],
      "source": [
        "# Import Spacy and french initialisation\n",
        "import fr_core_news_md\n",
        "nlp = fr_core_news_md.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQL-RX0KHb-F"
      },
      "source": [
        "3. Import french STOP_WORDS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TZNd26-z1xIT"
      },
      "outputs": [],
      "source": [
        "# Import Stop words \n",
        "from spacy.lang.fr.stop_words import STOP_WORDS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgT6StTqmoNt"
      },
      "source": [
        "4. Try the `nlp` function on the following sentence `\"je la laisse, je veux la laisser, je l'ai laissée, je me suis laissé aller\"`, and extract the lemma using a list comprehension, what happened to the words in the sentence?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rX8rL0BwOmou"
      },
      "outputs": [],
      "source": [
        "a = nlp(\"je la laisse, je veux la laisser, je l'ai laissée, je me suis laissé aller\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['je',\n",
              " 'le',\n",
              " 'laisse',\n",
              " ',',\n",
              " 'je',\n",
              " 'vouloir',\n",
              " 'le',\n",
              " 'laisser',\n",
              " ',',\n",
              " 'je',\n",
              " \"l'\",\n",
              " 'avoir',\n",
              " 'laisser',\n",
              " ',',\n",
              " 'je',\n",
              " 'me',\n",
              " 'être',\n",
              " 'laisser',\n",
              " 'aller']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[element.lemma_ for element in a]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQFRoLUSnWcm"
      },
      "source": [
        "All the words are replaced by a common representation, the reason why the word `\"laisse\"` has not been replaced by the infinitive form is that it is a homonym to the noun `\"laisse\"`, lemmatization is sometimes sensitive to ambiguity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrkXKRjlfyib"
      },
      "source": [
        "5. You will now have to clean our texts in order to prepare them for training.\n",
        "Let's do this in three different steps :\n",
        " * using the command `str.isalnum` remove all characters from your strings that are not alphanumeric except for whitespaces, and apostrophies.\n",
        " * using `str.replace`, `str.lower` and `str.strip` replace double whitespaces with single whitespaces, convert all characters to lowercase and trim starting and finishing whitespaces.\n",
        " * using spacy, replace all tokens in your texts with `lemma_` and remove all the stop words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>stars</th>\n",
              "      <th>review_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Génial, fabuleux, exceptionnel ! J'aimerais qu...</td>\n",
              "      <td>5</td>\n",
              "      <td>génial fabuleux exceptionnel   aimer walt disn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Toujours aussi magic, féerique !</td>\n",
              "      <td>5</td>\n",
              "      <td>magic féerique</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>En vacances en région parisienne nous nous som...</td>\n",
              "      <td>2</td>\n",
              "      <td>vacance région parisien décider visiter parc r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Tropbeaufinalpleinlesyeuxoreil</td>\n",
              "      <td>5</td>\n",
              "      <td>tropbeaufinalpleinlesyeuxoreil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>L'univers Disney reste merveilleux. Toutefois ...</td>\n",
              "      <td>4</td>\n",
              "      <td>univers disney merveilleux toutefois regrette ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295057</th>\n",
              "      <td>Toujours aussi magique même si à la fin du séj...</td>\n",
              "      <td>5</td>\n",
              "      <td>magique fin séjour rotule lol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295549</th>\n",
              "      <td>Séjour au top!!! Mes enfants les plus heureux ...</td>\n",
              "      <td>5</td>\n",
              "      <td>séjour top enfant heureux vouloir voir personn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298475</th>\n",
              "      <td>Magnifique un monde parfait &lt;span class=\"\"\"\"_4...</td>\n",
              "      <td>5</td>\n",
              "      <td>magnifique monde parfait span class47e3 5mfr t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298832</th>\n",
              "      <td>Oui j'ai aimé  car j'adore disney et tout ce q...</td>\n",
              "      <td>4</td>\n",
              "      <td>oui aimer   adore disney touche univers grand ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299402</th>\n",
              "      <td>Je vais à Disney minimum 1 fois par saison car...</td>\n",
              "      <td>5</td>\n",
              "      <td>disney minimum 1 fois saison magique printemps...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8474 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   review  stars  \\\n",
              "0       Génial, fabuleux, exceptionnel ! J'aimerais qu...      5   \n",
              "2                        Toujours aussi magic, féerique !      5   \n",
              "11      En vacances en région parisienne nous nous som...      2   \n",
              "12                         Tropbeaufinalpleinlesyeuxoreil      5   \n",
              "23      L'univers Disney reste merveilleux. Toutefois ...      4   \n",
              "...                                                   ...    ...   \n",
              "295057  Toujours aussi magique même si à la fin du séj...      5   \n",
              "295549  Séjour au top!!! Mes enfants les plus heureux ...      5   \n",
              "298475  Magnifique un monde parfait <span class=\"\"\"\"_4...      5   \n",
              "298832  Oui j'ai aimé  car j'adore disney et tout ce q...      4   \n",
              "299402  Je vais à Disney minimum 1 fois par saison car...      5   \n",
              "\n",
              "                                             review_clean  \n",
              "0       génial fabuleux exceptionnel   aimer walt disn...  \n",
              "2                                          magic féerique  \n",
              "11      vacance région parisien décider visiter parc r...  \n",
              "12                         tropbeaufinalpleinlesyeuxoreil  \n",
              "23      univers disney merveilleux toutefois regrette ...  \n",
              "...                                                   ...  \n",
              "295057                      magique fin séjour rotule lol  \n",
              "295549  séjour top enfant heureux vouloir voir personn...  \n",
              "298475  magnifique monde parfait span class47e3 5mfr t...  \n",
              "298832  oui aimer   adore disney touche univers grand ...  \n",
              "299402  disney minimum 1 fois saison magique printemps...  \n",
              "\n",
              "[8474 rows x 3 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "french_reviews[\"review_clean\"] = french_reviews[\"review\"].apply(lambda x:''.join(ch for ch in x if ch.isalnum() or ch==\" \" or ch==\"'\"))\n",
        "french_reviews[\"review_clean\"] = french_reviews[\"review_clean\"].apply(lambda x: x.replace(\" +\",\" \").lower().strip())\n",
        "french_reviews[\"review_clean\"] = french_reviews[\"review_clean\"].apply(lambda x: \" \".join([token.lemma_ for token in nlp(x) if (token.lemma_ not in STOP_WORDS) and (token.text not in STOP_WORDS)]))\n",
        "\n",
        "french_reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "4JE3FrlIq_a8",
        "outputId": "adc8db1a-0838-42df-ba50-ffdc4aa90cf5"
      },
      "outputs": [],
      "source": [
        "french_reviews = pd.read_csv(\"https://full-stack-bigdata-datasets.s3.eu-west-3.amazonaws.com/Deep+Learning/sentiment-analysis/french_reviews_clean.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "aSJVwigvV4Vm"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True     8467\n",
              "False       7\n",
              "Name: review_clean, dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mask = french_reviews.review_clean.apply(lambda x: type(x)==str)\n",
        "mask.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FEXJKqYqtzRu"
      },
      "outputs": [],
      "source": [
        "french_reviews = french_reviews.loc[mask,:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV1u8GZYhCLq"
      },
      "source": [
        "6. Using `tf.keras.preprocessing.text.Tokenizer` [Tokenizer](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer), process to encoding all the reviews (be careful, some reviews might have been entirely erased, try and understand why, remove those reviews)\n",
        "\n",
        "When instanciating the tokenizer, make sure you set it up to keep only the 1000 most common words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "oWowSu9ZqB8Y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=1000, oov_token=\"out_of_vocab\") # instanciate the tokenizer\n",
        "tokenizer.fit_on_texts(french_reviews.review_clean)\n",
        "french_reviews[\"review_encoded\"] = tokenizer.texts_to_sequences(french_reviews.review_clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "c0BhixF3Vauw",
        "outputId": "6d2c2974-842f-48d4-8ca8-e086db1c9d1a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>stars</th>\n",
              "      <th>review_clean</th>\n",
              "      <th>review_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Génial, fabuleux, exceptionnel ! J'aimerais qu...</td>\n",
              "      <td>5</td>\n",
              "      <td>génial fabuleux exceptionnel   aimer walt disn...</td>\n",
              "      <td>[111, 581, 484, 196, 466, 6, 1, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Toujours aussi magic, féerique !</td>\n",
              "      <td>5</td>\n",
              "      <td>magic féerique</td>\n",
              "      <td>[332, 77]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>En vacances en région parisienne nous nous som...</td>\n",
              "      <td>2</td>\n",
              "      <td>vacance région parisien décider visiter parc r...</td>\n",
              "      <td>[405, 1, 1, 807, 467, 3, 1, 1, 5, 352, 135, 3,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tropbeaufinalpleinlesyeuxoreil</td>\n",
              "      <td>5</td>\n",
              "      <td>tropbeaufinalpleinlesyeuxoreil</td>\n",
              "      <td>[1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>L'univers Disney reste merveilleux. Toutefois ...</td>\n",
              "      <td>4</td>\n",
              "      <td>univers disney merveilleux regrette falloir dé...</td>\n",
              "      <td>[378, 6, 93, 666, 65, 1, 114, 166, 1, 112, 667...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  stars  \\\n",
              "0  Génial, fabuleux, exceptionnel ! J'aimerais qu...      5   \n",
              "1                   Toujours aussi magic, féerique !      5   \n",
              "2  En vacances en région parisienne nous nous som...      2   \n",
              "3                     Tropbeaufinalpleinlesyeuxoreil      5   \n",
              "4  L'univers Disney reste merveilleux. Toutefois ...      4   \n",
              "\n",
              "                                        review_clean  \\\n",
              "0  génial fabuleux exceptionnel   aimer walt disn...   \n",
              "1                                     magic féerique   \n",
              "2  vacance région parisien décider visiter parc r...   \n",
              "3                     tropbeaufinalpleinlesyeuxoreil   \n",
              "4  univers disney merveilleux regrette falloir dé...   \n",
              "\n",
              "                                      review_encoded  \n",
              "0                 [111, 581, 484, 196, 466, 6, 1, 1]  \n",
              "1                                          [332, 77]  \n",
              "2  [405, 1, 1, 807, 467, 3, 1, 1, 5, 352, 135, 3,...  \n",
              "3                                                [1]  \n",
              "4  [378, 6, 93, 666, 65, 1, 114, 166, 1, 112, 667...  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "french_reviews.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWDcmw-ohmdM"
      },
      "source": [
        "7. Try and convert your texts and labels into a tensor slice dataset using `tf.data.Dataset.from_tensor_slices` (it should fail giving this error : `ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type list)`.)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "id": "tlwDyieOszdi",
        "outputId": "bb70ef7d-4449-4f5b-ea50-565c60181d3e"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type list).",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Berenger\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[1;34m(element, element_signature)\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m           \u001b[0mspec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_spec_from_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_fallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Berenger\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36mtype_spec_from_value\u001b[1;34m(element, use_fallback)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 485\u001b[1;33m   raise TypeError(\"Could not build a `TypeSpec` for {} with type {}\".format(\n\u001b[0m\u001b[0;32m    486\u001b[0m       \u001b[0melement\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mTypeError\u001b[0m: Could not build a `TypeSpec` for 0                      [111, 581, 484, 196, 466, 6, 1, 1]\n1                                               [332, 77]\n2       [405, 1, 1, 807, 467, 3, 1, 1, 5, 352, 135, 3,...\n3                                                     [1]\n4       [378, 6, 93, 666, 65, 1, 114, 166, 1, 112, 667...\n                              ...                        \n8469                                [11, 186, 29, 1, 477]\n8470    [29, 52, 17, 310, 102, 48, 57, 154, 29, 51, 33...\n8471    [22, 27, 183, 14, 43, 44, 45, 165, 7, 8, 63, 9...\n8472    [200, 943, 86, 6, 1, 378, 50, 17, 5, 29, 1, 59...\n8473    [6, 411, 109, 18, 321, 11, 1, 1, 21, 1, 79, 39...\nName: review_encoded, Length: 8467, dtype: object with type Series",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18140/1063304463.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfull_ds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrench_reviews\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreview_encoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrench_reviews\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mc:\\Users\\Berenger\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[1;34m(tensors, name)\u001b[0m\n\u001b[0;32m    791\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m     \"\"\"\n\u001b[1;32m--> 793\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m   \u001b[1;32mclass\u001b[0m \u001b[0m_GeneratorState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Berenger\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, element, is_files, name)\u001b[0m\n\u001b[0;32m   4475\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_files\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4476\u001b[0m     \u001b[1;34m\"\"\"See `Dataset.from_tensor_slices()` for details.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4477\u001b[1;33m     \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4478\u001b[0m     \u001b[0mbatched_spec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4479\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_batched_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatched_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Berenger\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[1;34m(element, element_signature)\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;31m# the value. As a fallback try converting the value to a tensor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         normalized_components.append(\n\u001b[1;32m--> 107\u001b[1;33m             ops.convert_to_tensor(t, name=\"component_%d\" % i))\n\u001b[0m\u001b[0;32m    108\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensorSpec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Berenger\\anaconda3\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Berenger\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1694\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1695\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1697\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Berenger\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    341\u001b[0m                                          as_ref=False):\n\u001b[0;32m    342\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Berenger\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m   \"\"\"\n\u001b[1;32m--> 267\u001b[1;33m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[0;32m    268\u001b[0m                         allow_broadcast=True)\n\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Berenger\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    277\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tf.constant\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Berenger\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m   \u001b[1;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m   \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Berenger\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
          ]
        }
      ],
      "source": [
        "full_ds = tf.data.Dataset.from_tensor_slices((french_reviews.review_encoded, french_reviews.stars.values-1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iWhGYhtim0_"
      },
      "source": [
        "8. This is perfectly normal, Tensorflow is incapable as of now to create a tensor dataset based on lists, we will have to store all of our encoded texts into a single numpy array before creating the tensorflow dataset.\n",
        "The problem is that not all our sequences are the same length, this is where the `tf.keras.preprocessing.sequence.pad_sequences` comes in handy, it will add zero padding at the beginning (`padding=\"pre\"`) or at the end (`padding=\"post\"`) of your sequences so they all have equal length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "lI8qSZloil3w"
      },
      "outputs": [],
      "source": [
        "reviews_pad = tf.keras.preprocessing.sequence.pad_sequences(french_reviews.review_encoded, padding=\"post\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ch6zwLZpW6i"
      },
      "source": [
        "9. Do a `train_test_split` of your data (keep about 70% in the train). For this you may use `sklearn.model_selection.train_test_split`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "uo7edz0PAr3v"
      },
      "outputs": [],
      "source": [
        "# Train Test Split\n",
        "xtrain, xval, ytrain, yval = train_test_split(reviews_pad,french_reviews.stars, test_size=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YBVKh6XjY6X"
      },
      "source": [
        "10. Now that your sequences are padded create the tensor dataset for the training, and validation set. The target variable is qualitative ordinal, this means you may treat the sentiment analysis problem as a regression problem.\n",
        "However you may choose to adopt a classification approach, in this case make sure you modify the stars column so that the scores go from 0 to 4 instead of 1 to 5 to avoid errors when setting up your model's architecture and the loss function. (Since this is a multiple classification problem, we will use SparseCategoricalCrossentropy which assumes that the first label is 0)\n",
        "\n",
        "The solution will first use the regression approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "3_-Oldl3jlUl"
      },
      "outputs": [],
      "source": [
        "train = tf.data.Dataset.from_tensor_slices((xtrain, ytrain))\n",
        "val = tf.data.Dataset.from_tensor_slices((xval, yval))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCCcF5rJ_o25"
      },
      "source": [
        "11. Once you have done this you may use `.shuffle` on the train set, and `.batch`on both sets to organise them by batches of 64 observations.\n",
        "\n",
        "* [shuffle documentation](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle)\n",
        "\n",
        "* [batch documentation](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "HClAccyNCyRc"
      },
      "outputs": [],
      "source": [
        "train_batch = train.shuffle(len(train)).batch(64)\n",
        "val_batch = val.shuffle(len(val)).batch(64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpUQB9xApckV"
      },
      "source": [
        "12. Look at a batch of data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8jxCfSSOUZ_",
        "outputId": "8d3e7429-e811-4b3d-96d3-8fa712a139f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 28 158  10 ...   0   0   0]\n",
            " [383 836  84 ...   0   0   0]\n",
            " [  1 950   5 ...   0   0   0]\n",
            " ...\n",
            " [118 767 103 ...   0   0   0]\n",
            " [ 11  17 311 ...   0   0   0]\n",
            " [114  27   2 ...   0   0   0]], shape=(64, 443), dtype=int32) tf.Tensor(\n",
            "[3 2 1 5 5 3 5 4 1 1 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 2 3 5 5 5 4 5 4 5 5 5\n",
            " 5 5 2 5 5 5 5 4 5 5 5 4 2 3 5 5 4 5 5 5 5 5 5 5 5 3 3], shape=(64,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        " # Regardons un batch \n",
        "for review, star in train_batch.take(1):\n",
        "  print(review, star)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMaPEPk6QS4x"
      },
      "source": [
        "## Modeling\n",
        "\n",
        "Let's create a model in order to train an embedding!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD3n6l1TplDN"
      },
      "source": [
        "1. Follow a similar architecture to the one we used in the code embedding demonstration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "kYxNpFYEUWI4"
      },
      "outputs": [],
      "source": [
        "vocab_size = tokenizer.num_words\n",
        "model = tf.keras.Sequential([\n",
        "                  # Couche d'Input Word Embedding           \n",
        "                  tf.keras.layers.Embedding(vocab_size+1, 8, input_shape=[review.shape[1],],name=\"embedding\"),\n",
        "                  # Gobal average pooling\n",
        "                  tf.keras.layers.GlobalAveragePooling1D(),\n",
        "\n",
        "                  # Couche Dense classique\n",
        "                  tf.keras.layers.Dense(16, activation='relu'),\n",
        "\n",
        "                  # Couche de sortie avec le nombre de neurones en sortie égale au nombre de classe avec fonction softmax\n",
        "                  tf.keras.layers.Dense(1, activation=\"linear\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 443, 8)            8008      \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 8)                0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                144       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,169\n",
            "Trainable params: 8,169\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-gKYS4_pu8I"
      },
      "source": [
        "2. Compile your model with the correct loss function, and the Adam optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "yOXk9F0YQ0j5"
      },
      "outputs": [],
      "source": [
        "optimizer= tf.keras.optimizers.Adam()\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=tf.keras.losses.MeanSquaredError(),\n",
        "              metrics=[tf.keras.metrics.MeanAbsoluteError()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5Rsbpckp3jK"
      },
      "source": [
        "3. Fit your model on 20 epochs with weights to penalize too frequent notes. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qvWNK09RAPR",
        "outputId": "97df47ee-3f53-4cdb-e295-89880f73a10c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "93/93 [==============================] - 1s 6ms/step - loss: 16.5261 - mean_absolute_error: 3.8697 - val_loss: 13.1125 - val_mean_absolute_error: 3.4101\n",
            "Epoch 2/20\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 7.7112 - mean_absolute_error: 2.5231 - val_loss: 2.6057 - val_mean_absolute_error: 1.4687\n",
            "Epoch 3/20\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 1.6491 - mean_absolute_error: 1.0889 - val_loss: 1.4284 - val_mean_absolute_error: 0.9551\n",
            "Epoch 4/20\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 1.4327 - mean_absolute_error: 0.9587 - val_loss: 1.3989 - val_mean_absolute_error: 0.9478\n",
            "Epoch 5/20\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 1.4069 - mean_absolute_error: 0.9504 - val_loss: 1.3749 - val_mean_absolute_error: 0.9287\n",
            "Epoch 6/20\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 1.3838 - mean_absolute_error: 0.9357 - val_loss: 1.3497 - val_mean_absolute_error: 0.9299\n",
            "Epoch 7/20\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 1.3621 - mean_absolute_error: 0.9335 - val_loss: 1.3286 - val_mean_absolute_error: 0.9126\n",
            "Epoch 8/20\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 1.3417 - mean_absolute_error: 0.9190 - val_loss: 1.3085 - val_mean_absolute_error: 0.9165\n",
            "Epoch 9/20\n",
            "93/93 [==============================] - 0s 5ms/step - loss: 1.3222 - mean_absolute_error: 0.9146 - val_loss: 1.2892 - val_mean_absolute_error: 0.8969\n",
            "Epoch 10/20\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 1.3049 - mean_absolute_error: 0.9063 - val_loss: 1.2708 - val_mean_absolute_error: 0.8947\n",
            "Epoch 11/20\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 1.2868 - mean_absolute_error: 0.8966 - val_loss: 1.2538 - val_mean_absolute_error: 0.8913\n",
            "Epoch 12/20\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 1.2697 - mean_absolute_error: 0.8899 - val_loss: 1.2385 - val_mean_absolute_error: 0.8888\n",
            "Epoch 13/20\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 1.2530 - mean_absolute_error: 0.8837 - val_loss: 1.2223 - val_mean_absolute_error: 0.8627\n",
            "Epoch 14/20\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 1.2363 - mean_absolute_error: 0.8747 - val_loss: 1.2062 - val_mean_absolute_error: 0.8584\n",
            "Epoch 15/20\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 1.2204 - mean_absolute_error: 0.8672 - val_loss: 1.1915 - val_mean_absolute_error: 0.8497\n",
            "Epoch 16/20\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 1.2044 - mean_absolute_error: 0.8604 - val_loss: 1.1764 - val_mean_absolute_error: 0.8488\n",
            "Epoch 17/20\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 1.1886 - mean_absolute_error: 0.8522 - val_loss: 1.1620 - val_mean_absolute_error: 0.8421\n",
            "Epoch 18/20\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 1.1725 - mean_absolute_error: 0.8435 - val_loss: 1.1479 - val_mean_absolute_error: 0.8309\n",
            "Epoch 19/20\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 1.1562 - mean_absolute_error: 0.8357 - val_loss: 1.1339 - val_mean_absolute_error: 0.8344\n",
            "Epoch 20/20\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 1.1401 - mean_absolute_error: 0.8286 - val_loss: 1.1191 - val_mean_absolute_error: 0.8269\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_batch, \n",
        "                    epochs=20, \n",
        "                    validation_data=val_batch,\n",
        "                    callbacks=[tensorboard_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDnsfUFQTkyJ"
      },
      "source": [
        "## Evaluation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Exbx9Bms-xZ"
      },
      "source": [
        "1. Create a graph showing your loss in relation to the number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualization of the training process on the loss function \n",
        "plt.plot(history.history[\"loss\"], color=\"b\")\n",
        "plt.plot(history.history[\"val_loss\"], color=\"r\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzFU7VcMtF2j"
      },
      "source": [
        "2. Create a graph showing your accuracy in relation to the number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "D96WZP8cVOFL",
        "outputId": "a2f5ce14-1e87-4a3b-a01a-0d7136cc79ed"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualization of accuracy training \n",
        "plt.plot(history.history[\"mean_absolute_error\"], color=\"b\")\n",
        "plt.plot(history.history[\"val_mean_absolute_error\"], color=\"r\")\n",
        "plt.ylabel(\"mean_absolute_error\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-df8673c17f9d5b4f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-df8673c17f9d5b4f\");\n",
              "          const url = new URL(\"/\", window.location);\n",
              "          const port = 4;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#docs_infra: no_execute\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs --port=0004"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0MwYOxorUFl"
      },
      "source": [
        "3. Write to file the weights on the embedding layer and the 1000 most common words registered by the tokenizer. You can help yourself to the code in the code embedding demonstration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "mSWkyJJPY7r6"
      },
      "outputs": [],
      "source": [
        "vocab = [value for value in tokenizer.index_word.values()]\n",
        "vocab = vocab[:1000]\n",
        "weights = model.get_layer('embedding').get_weights()[0]\n",
        "\n",
        "log_dir = \"/content/logs/embed\"\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "out_v = io.open(log_dir+\"/vectors.tsv\", 'w', encoding='utf-8')\n",
        "out_m = io.open(log_dir+\"/metadata.tsv\", 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(vocab):\n",
        "  if index == 0:\n",
        "    continue  # skip 0, it's padding.\n",
        "  vec = weights[index]\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  out_m.write(word + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "124fXGFCr3ZR"
      },
      "source": [
        "4. Go to [the embedding projector](https://projector.tensorflow.org/) in order to visualize the embedding, what do you think?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "train = tf.data.Dataset.from_tensor_slices((xtrain, ytrain-1))\n",
        "val = tf.data.Dataset.from_tensor_slices((xval, yval-1))\n",
        "train_batch = train.shuffle(len(train)).batch(64)\n",
        "val_batch = val.shuffle(len(val)).batch(64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab_size = tokenizer.num_words\n",
        "model = tf.keras.Sequential([\n",
        "                  # Couche d'Input Word Embedding           \n",
        "                  tf.keras.layers.Embedding(vocab_size+1, 8, input_shape=[review.shape[1],],name=\"embedding\"),\n",
        "                  # Gobal average pooling\n",
        "                  tf.keras.layers.GlobalAveragePooling1D(),\n",
        "\n",
        "                  # Couche Dense classique\n",
        "                  tf.keras.layers.Dense(16, activation='relu'),\n",
        "\n",
        "                  # Couche de sortie avec le nombre de neurones en sortie égale au nombre de classe avec fonction softmax\n",
        "                  tf.keras.layers.Dense(5, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 443, 8)            8008      \n",
            "                                                                 \n",
            " global_average_pooling1d_1   (None, 8)                0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16)                144       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 85        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,237\n",
            "Trainable params: 8,237\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimizer= tf.keras.optimizers.Adam()\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy(), tf.keras.metrics.MeanAbsoluteError()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "93/93 [==============================] - 1s 5ms/step - loss: 1.5274 - sparse_categorical_accuracy: 0.5307 - mean_absolute_error: 2.9742 - val_loss: 1.4055 - val_sparse_categorical_accuracy: 0.5687 - val_mean_absolute_error: 2.9625\n",
            "Epoch 2/100\n",
            "93/93 [==============================] - 0s 5ms/step - loss: 1.2727 - sparse_categorical_accuracy: 0.5791 - mean_absolute_error: 2.9742 - val_loss: 1.2259 - val_sparse_categorical_accuracy: 0.5687 - val_mean_absolute_error: 2.9625\n",
            "Epoch 3/100\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 1.2087 - sparse_categorical_accuracy: 0.5791 - mean_absolute_error: 2.9742 - val_loss: 1.2164 - val_sparse_categorical_accuracy: 0.5687 - val_mean_absolute_error: 2.9625\n",
            "Epoch 4/100\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 1.2022 - sparse_categorical_accuracy: 0.5791 - mean_absolute_error: 2.9742 - val_loss: 1.2098 - val_sparse_categorical_accuracy: 0.5687 - val_mean_absolute_error: 2.9625\n",
            "Epoch 5/100\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 1.1951 - sparse_categorical_accuracy: 0.5791 - mean_absolute_error: 2.9742 - val_loss: 1.2004 - val_sparse_categorical_accuracy: 0.5687 - val_mean_absolute_error: 2.9625\n",
            "Epoch 6/100\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 1.1867 - sparse_categorical_accuracy: 0.5791 - mean_absolute_error: 2.9742 - val_loss: 1.1894 - val_sparse_categorical_accuracy: 0.5687 - val_mean_absolute_error: 2.9625\n",
            "Epoch 7/100\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 1.1743 - sparse_categorical_accuracy: 0.5793 - mean_absolute_error: 2.9742 - val_loss: 1.1756 - val_sparse_categorical_accuracy: 0.5687 - val_mean_absolute_error: 2.9625\n",
            "Epoch 8/100\n",
            "93/93 [==============================] - 0s 5ms/step - loss: 1.1594 - sparse_categorical_accuracy: 0.5800 - mean_absolute_error: 2.9742 - val_loss: 1.1593 - val_sparse_categorical_accuracy: 0.5699 - val_mean_absolute_error: 2.9625\n",
            "Epoch 9/100\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 1.1424 - sparse_categorical_accuracy: 0.5798 - mean_absolute_error: 2.9742 - val_loss: 1.1395 - val_sparse_categorical_accuracy: 0.5714 - val_mean_absolute_error: 2.9625\n",
            "Epoch 10/100\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 1.1226 - sparse_categorical_accuracy: 0.5812 - mean_absolute_error: 2.9742 - val_loss: 1.1198 - val_sparse_categorical_accuracy: 0.5742 - val_mean_absolute_error: 2.9625\n",
            "Epoch 11/100\n",
            "93/93 [==============================] - 1s 6ms/step - loss: 1.1036 - sparse_categorical_accuracy: 0.5859 - mean_absolute_error: 2.9742 - val_loss: 1.1013 - val_sparse_categorical_accuracy: 0.5769 - val_mean_absolute_error: 2.9625\n",
            "Epoch 12/100\n",
            "93/93 [==============================] - 1s 6ms/step - loss: 1.0841 - sparse_categorical_accuracy: 0.5881 - mean_absolute_error: 2.9742 - val_loss: 1.0903 - val_sparse_categorical_accuracy: 0.5777 - val_mean_absolute_error: 2.9625\n",
            "Epoch 13/100\n",
            "93/93 [==============================] - 1s 6ms/step - loss: 1.0707 - sparse_categorical_accuracy: 0.5916 - mean_absolute_error: 2.9742 - val_loss: 1.0716 - val_sparse_categorical_accuracy: 0.5832 - val_mean_absolute_error: 2.9625\n",
            "Epoch 14/100\n",
            "93/93 [==============================] - 1s 5ms/step - loss: 1.0537 - sparse_categorical_accuracy: 0.5958 - mean_absolute_error: 2.9742 - val_loss: 1.0592 - val_sparse_categorical_accuracy: 0.5899 - val_mean_absolute_error: 2.9625\n",
            "Epoch 15/100\n",
            "93/93 [==============================] - 1s 6ms/step - loss: 1.0404 - sparse_categorical_accuracy: 0.6023 - mean_absolute_error: 2.9742 - val_loss: 1.0441 - val_sparse_categorical_accuracy: 0.5911 - val_mean_absolute_error: 2.9625\n",
            "Epoch 16/100\n",
            "93/93 [==============================] - 1s 6ms/step - loss: 1.0281 - sparse_categorical_accuracy: 0.6028 - mean_absolute_error: 2.9742 - val_loss: 1.0318 - val_sparse_categorical_accuracy: 0.5946 - val_mean_absolute_error: 2.9625\n",
            "Epoch 17/100\n",
            "93/93 [==============================] - 1s 6ms/step - loss: 1.0140 - sparse_categorical_accuracy: 0.6073 - mean_absolute_error: 2.9742 - val_loss: 1.0205 - val_sparse_categorical_accuracy: 0.5998 - val_mean_absolute_error: 2.9625\n",
            "Epoch 18/100\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 1.0024 - sparse_categorical_accuracy: 0.6087 - mean_absolute_error: 2.9742 - val_loss: 1.0099 - val_sparse_categorical_accuracy: 0.6006 - val_mean_absolute_error: 2.9625\n",
            "Epoch 19/100\n",
            "93/93 [==============================] - 1s 6ms/step - loss: 0.9911 - sparse_categorical_accuracy: 0.6126 - mean_absolute_error: 2.9742 - val_loss: 1.0008 - val_sparse_categorical_accuracy: 0.6013 - val_mean_absolute_error: 2.9625\n",
            "Epoch 20/100\n",
            "93/93 [==============================] - 0s 5ms/step - loss: 0.9810 - sparse_categorical_accuracy: 0.6171 - mean_absolute_error: 2.9742 - val_loss: 0.9954 - val_sparse_categorical_accuracy: 0.6084 - val_mean_absolute_error: 2.9625\n",
            "Epoch 21/100\n",
            "93/93 [==============================] - 1s 6ms/step - loss: 0.9704 - sparse_categorical_accuracy: 0.6201 - mean_absolute_error: 2.9742 - val_loss: 0.9801 - val_sparse_categorical_accuracy: 0.6128 - val_mean_absolute_error: 2.9625\n",
            "Epoch 22/100\n",
            "93/93 [==============================] - 1s 6ms/step - loss: 0.9595 - sparse_categorical_accuracy: 0.6239 - mean_absolute_error: 2.9742 - val_loss: 0.9727 - val_sparse_categorical_accuracy: 0.6128 - val_mean_absolute_error: 2.9625\n",
            "Epoch 23/100\n",
            "93/93 [==============================] - 1s 5ms/step - loss: 0.9505 - sparse_categorical_accuracy: 0.6271 - mean_absolute_error: 2.9742 - val_loss: 0.9701 - val_sparse_categorical_accuracy: 0.6116 - val_mean_absolute_error: 2.9625\n",
            "Epoch 24/100\n",
            "93/93 [==============================] - 1s 6ms/step - loss: 0.9423 - sparse_categorical_accuracy: 0.6269 - mean_absolute_error: 2.9742 - val_loss: 0.9583 - val_sparse_categorical_accuracy: 0.6187 - val_mean_absolute_error: 2.9625\n",
            "Epoch 25/100\n",
            "93/93 [==============================] - 0s 5ms/step - loss: 0.9333 - sparse_categorical_accuracy: 0.6311 - mean_absolute_error: 2.9742 - val_loss: 0.9511 - val_sparse_categorical_accuracy: 0.6242 - val_mean_absolute_error: 2.9625\n",
            "Epoch 26/100\n",
            "93/93 [==============================] - 1s 6ms/step - loss: 0.9269 - sparse_categorical_accuracy: 0.6321 - mean_absolute_error: 2.9742 - val_loss: 0.9489 - val_sparse_categorical_accuracy: 0.6190 - val_mean_absolute_error: 2.9625\n",
            "Epoch 27/100\n",
            "93/93 [==============================] - 1s 6ms/step - loss: 0.9209 - sparse_categorical_accuracy: 0.6350 - mean_absolute_error: 2.9742 - val_loss: 0.9419 - val_sparse_categorical_accuracy: 0.6265 - val_mean_absolute_error: 2.9625\n",
            "Epoch 28/100\n",
            "93/93 [==============================] - 1s 6ms/step - loss: 0.9155 - sparse_categorical_accuracy: 0.6374 - mean_absolute_error: 2.9742 - val_loss: 0.9428 - val_sparse_categorical_accuracy: 0.6222 - val_mean_absolute_error: 2.9625\n",
            "Epoch 29/100\n",
            "93/93 [==============================] - 0s 5ms/step - loss: 0.9094 - sparse_categorical_accuracy: 0.6397 - mean_absolute_error: 2.9742 - val_loss: 0.9367 - val_sparse_categorical_accuracy: 0.6230 - val_mean_absolute_error: 2.9625\n",
            "Epoch 30/100\n",
            "93/93 [==============================] - 1s 6ms/step - loss: 0.9060 - sparse_categorical_accuracy: 0.6426 - mean_absolute_error: 2.9742 - val_loss: 0.9335 - val_sparse_categorical_accuracy: 0.6257 - val_mean_absolute_error: 2.9625\n",
            "Epoch 31/100\n",
            "93/93 [==============================] - 1s 6ms/step - loss: 0.9006 - sparse_categorical_accuracy: 0.6431 - mean_absolute_error: 2.9742 - val_loss: 0.9350 - val_sparse_categorical_accuracy: 0.6309 - val_mean_absolute_error: 2.9625\n",
            "Epoch 32/100\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.8974 - sparse_categorical_accuracy: 0.6423 - mean_absolute_error: 2.9742 - val_loss: 0.9288 - val_sparse_categorical_accuracy: 0.6309 - val_mean_absolute_error: 2.9625\n",
            "Epoch 33/100\n",
            "93/93 [==============================] - 1s 6ms/step - loss: 0.8938 - sparse_categorical_accuracy: 0.6466 - mean_absolute_error: 2.9742 - val_loss: 0.9270 - val_sparse_categorical_accuracy: 0.6316 - val_mean_absolute_error: 2.9625\n",
            "Epoch 34/100\n",
            "93/93 [==============================] - 0s 5ms/step - loss: 0.8916 - sparse_categorical_accuracy: 0.6487 - mean_absolute_error: 2.9742 - val_loss: 0.9243 - val_sparse_categorical_accuracy: 0.6289 - val_mean_absolute_error: 2.9625\n",
            "Epoch 35/100\n",
            "93/93 [==============================] - 1s 5ms/step - loss: 0.8873 - sparse_categorical_accuracy: 0.6487 - mean_absolute_error: 2.9742 - val_loss: 0.9233 - val_sparse_categorical_accuracy: 0.6348 - val_mean_absolute_error: 2.9625\n",
            "Epoch 36/100\n",
            "93/93 [==============================] - 1s 6ms/step - loss: 0.8864 - sparse_categorical_accuracy: 0.6497 - mean_absolute_error: 2.9742 - val_loss: 0.9273 - val_sparse_categorical_accuracy: 0.6352 - val_mean_absolute_error: 2.9625\n",
            "Epoch 37/100\n",
            "93/93 [==============================] - 1s 6ms/step - loss: 0.8833 - sparse_categorical_accuracy: 0.6532 - mean_absolute_error: 2.9742 - val_loss: 0.9203 - val_sparse_categorical_accuracy: 0.6320 - val_mean_absolute_error: 2.9625\n",
            "Epoch 38/100\n",
            "93/93 [==============================] - 0s 5ms/step - loss: 0.8803 - sparse_categorical_accuracy: 0.6537 - mean_absolute_error: 2.9742 - val_loss: 0.9196 - val_sparse_categorical_accuracy: 0.6312 - val_mean_absolute_error: 2.9625\n",
            "Epoch 39/100\n",
            "93/93 [==============================] - 0s 5ms/step - loss: 0.8773 - sparse_categorical_accuracy: 0.6527 - mean_absolute_error: 2.9742 - val_loss: 0.9225 - val_sparse_categorical_accuracy: 0.6336 - val_mean_absolute_error: 2.9625\n",
            "Epoch 40/100\n",
            "93/93 [==============================] - 1s 6ms/step - loss: 0.8756 - sparse_categorical_accuracy: 0.6546 - mean_absolute_error: 2.9742 - val_loss: 0.9191 - val_sparse_categorical_accuracy: 0.6312 - val_mean_absolute_error: 2.9625\n",
            "Epoch 41/100\n",
            "93/93 [==============================] - 1s 6ms/step - loss: 0.8728 - sparse_categorical_accuracy: 0.6564 - mean_absolute_error: 2.9742 - val_loss: 0.9189 - val_sparse_categorical_accuracy: 0.6375 - val_mean_absolute_error: 2.9625\n",
            "Epoch 42/100\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.8707 - sparse_categorical_accuracy: 0.6583 - mean_absolute_error: 2.9742 - val_loss: 0.9169 - val_sparse_categorical_accuracy: 0.6348 - val_mean_absolute_error: 2.9625\n",
            "Epoch 43/100\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 0.8700 - sparse_categorical_accuracy: 0.6581 - mean_absolute_error: 2.9742 - val_loss: 0.9163 - val_sparse_categorical_accuracy: 0.6356 - val_mean_absolute_error: 2.9625\n",
            "Epoch 44/100\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 0.8677 - sparse_categorical_accuracy: 0.6605 - mean_absolute_error: 2.9742 - val_loss: 0.9164 - val_sparse_categorical_accuracy: 0.6328 - val_mean_absolute_error: 2.9625\n",
            "Epoch 45/100\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 0.8655 - sparse_categorical_accuracy: 0.6596 - mean_absolute_error: 2.9742 - val_loss: 0.9187 - val_sparse_categorical_accuracy: 0.6340 - val_mean_absolute_error: 2.9625\n",
            "Epoch 46/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.8640 - sparse_categorical_accuracy: 0.6613 - mean_absolute_error: 2.9742 - val_loss: 0.9163 - val_sparse_categorical_accuracy: 0.6340 - val_mean_absolute_error: 2.9625\n",
            "Epoch 47/100\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 0.8638 - sparse_categorical_accuracy: 0.6585 - mean_absolute_error: 2.9742 - val_loss: 0.9200 - val_sparse_categorical_accuracy: 0.6340 - val_mean_absolute_error: 2.9625\n",
            "Epoch 48/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.8611 - sparse_categorical_accuracy: 0.6601 - mean_absolute_error: 2.9742 - val_loss: 0.9154 - val_sparse_categorical_accuracy: 0.6383 - val_mean_absolute_error: 2.9625\n",
            "Epoch 49/100\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 0.8594 - sparse_categorical_accuracy: 0.6595 - mean_absolute_error: 2.9742 - val_loss: 0.9144 - val_sparse_categorical_accuracy: 0.6383 - val_mean_absolute_error: 2.9625\n",
            "Epoch 50/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.8570 - sparse_categorical_accuracy: 0.6630 - mean_absolute_error: 2.9742 - val_loss: 0.9156 - val_sparse_categorical_accuracy: 0.6395 - val_mean_absolute_error: 2.9625\n",
            "Epoch 51/100\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 0.8553 - sparse_categorical_accuracy: 0.6618 - mean_absolute_error: 2.9742 - val_loss: 0.9138 - val_sparse_categorical_accuracy: 0.6391 - val_mean_absolute_error: 2.9625\n",
            "Epoch 52/100\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 0.8537 - sparse_categorical_accuracy: 0.6628 - mean_absolute_error: 2.9742 - val_loss: 0.9139 - val_sparse_categorical_accuracy: 0.6364 - val_mean_absolute_error: 2.9625\n",
            "Epoch 53/100\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 0.8521 - sparse_categorical_accuracy: 0.6649 - mean_absolute_error: 2.9742 - val_loss: 0.9140 - val_sparse_categorical_accuracy: 0.6372 - val_mean_absolute_error: 2.9625\n",
            "Epoch 54/100\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 0.8510 - sparse_categorical_accuracy: 0.6669 - mean_absolute_error: 2.9742 - val_loss: 0.9154 - val_sparse_categorical_accuracy: 0.6399 - val_mean_absolute_error: 2.9625\n",
            "Epoch 55/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.8504 - sparse_categorical_accuracy: 0.6654 - mean_absolute_error: 2.9742 - val_loss: 0.9219 - val_sparse_categorical_accuracy: 0.6387 - val_mean_absolute_error: 2.9625\n",
            "Epoch 56/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.8481 - sparse_categorical_accuracy: 0.6676 - mean_absolute_error: 2.9742 - val_loss: 0.9170 - val_sparse_categorical_accuracy: 0.6375 - val_mean_absolute_error: 2.9625\n",
            "Epoch 57/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.8472 - sparse_categorical_accuracy: 0.6645 - mean_absolute_error: 2.9742 - val_loss: 0.9139 - val_sparse_categorical_accuracy: 0.6399 - val_mean_absolute_error: 2.9625\n",
            "Epoch 58/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.8485 - sparse_categorical_accuracy: 0.6650 - mean_absolute_error: 2.9742 - val_loss: 0.9133 - val_sparse_categorical_accuracy: 0.6391 - val_mean_absolute_error: 2.9625\n",
            "Epoch 59/100\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 0.8445 - sparse_categorical_accuracy: 0.6666 - mean_absolute_error: 2.9742 - val_loss: 0.9168 - val_sparse_categorical_accuracy: 0.6391 - val_mean_absolute_error: 2.9625\n",
            "Epoch 60/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.8432 - sparse_categorical_accuracy: 0.6699 - mean_absolute_error: 2.9742 - val_loss: 0.9138 - val_sparse_categorical_accuracy: 0.6395 - val_mean_absolute_error: 2.9625\n",
            "Epoch 61/100\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 0.8412 - sparse_categorical_accuracy: 0.6677 - mean_absolute_error: 2.9742 - val_loss: 0.9154 - val_sparse_categorical_accuracy: 0.6403 - val_mean_absolute_error: 2.9625\n",
            "Epoch 62/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.8428 - sparse_categorical_accuracy: 0.6655 - mean_absolute_error: 2.9742 - val_loss: 0.9137 - val_sparse_categorical_accuracy: 0.6411 - val_mean_absolute_error: 2.9625\n",
            "Epoch 63/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.8389 - sparse_categorical_accuracy: 0.6696 - mean_absolute_error: 2.9742 - val_loss: 0.9144 - val_sparse_categorical_accuracy: 0.6403 - val_mean_absolute_error: 2.9625\n",
            "Epoch 64/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.8387 - sparse_categorical_accuracy: 0.6681 - mean_absolute_error: 2.9742 - val_loss: 0.9189 - val_sparse_categorical_accuracy: 0.6395 - val_mean_absolute_error: 2.9625\n",
            "Epoch 65/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.8364 - sparse_categorical_accuracy: 0.6689 - mean_absolute_error: 2.9742 - val_loss: 0.9154 - val_sparse_categorical_accuracy: 0.6458 - val_mean_absolute_error: 2.9625\n",
            "Epoch 66/100\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 0.8371 - sparse_categorical_accuracy: 0.6691 - mean_absolute_error: 2.9742 - val_loss: 0.9136 - val_sparse_categorical_accuracy: 0.6434 - val_mean_absolute_error: 2.9625\n",
            "Epoch 67/100\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 0.8354 - sparse_categorical_accuracy: 0.6718 - mean_absolute_error: 2.9742 - val_loss: 0.9156 - val_sparse_categorical_accuracy: 0.6387 - val_mean_absolute_error: 2.9625\n",
            "Epoch 68/100\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 0.8330 - sparse_categorical_accuracy: 0.6720 - mean_absolute_error: 2.9742 - val_loss: 0.9138 - val_sparse_categorical_accuracy: 0.6450 - val_mean_absolute_error: 2.9625\n",
            "Epoch 69/100\n",
            "93/93 [==============================] - 1s 6ms/step - loss: 0.8330 - sparse_categorical_accuracy: 0.6691 - mean_absolute_error: 2.9742 - val_loss: 0.9281 - val_sparse_categorical_accuracy: 0.6375 - val_mean_absolute_error: 2.9625\n",
            "Epoch 70/100\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 0.8336 - sparse_categorical_accuracy: 0.6698 - mean_absolute_error: 2.9742 - val_loss: 0.9150 - val_sparse_categorical_accuracy: 0.6395 - val_mean_absolute_error: 2.9625\n",
            "Epoch 71/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.8309 - sparse_categorical_accuracy: 0.6731 - mean_absolute_error: 2.9742 - val_loss: 0.9142 - val_sparse_categorical_accuracy: 0.6419 - val_mean_absolute_error: 2.9625\n",
            "Epoch 72/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.8304 - sparse_categorical_accuracy: 0.6704 - mean_absolute_error: 2.9742 - val_loss: 0.9135 - val_sparse_categorical_accuracy: 0.6462 - val_mean_absolute_error: 2.9625\n",
            "Epoch 73/100\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 0.8308 - sparse_categorical_accuracy: 0.6704 - mean_absolute_error: 2.9742 - val_loss: 0.9136 - val_sparse_categorical_accuracy: 0.6411 - val_mean_absolute_error: 2.9625\n",
            "Epoch 74/100\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 0.8255 - sparse_categorical_accuracy: 0.6745 - mean_absolute_error: 2.9742 - val_loss: 0.9143 - val_sparse_categorical_accuracy: 0.6494 - val_mean_absolute_error: 2.9625\n",
            "Epoch 75/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.8251 - sparse_categorical_accuracy: 0.6753 - mean_absolute_error: 2.9742 - val_loss: 0.9156 - val_sparse_categorical_accuracy: 0.6403 - val_mean_absolute_error: 2.9625\n",
            "Epoch 76/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.8267 - sparse_categorical_accuracy: 0.6726 - mean_absolute_error: 2.9742 - val_loss: 0.9158 - val_sparse_categorical_accuracy: 0.6399 - val_mean_absolute_error: 2.9625\n",
            "Epoch 77/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.8237 - sparse_categorical_accuracy: 0.6779 - mean_absolute_error: 2.9742 - val_loss: 0.9144 - val_sparse_categorical_accuracy: 0.6431 - val_mean_absolute_error: 2.9625\n",
            "Epoch 78/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.8228 - sparse_categorical_accuracy: 0.6775 - mean_absolute_error: 2.9742 - val_loss: 0.9154 - val_sparse_categorical_accuracy: 0.6423 - val_mean_absolute_error: 2.9625\n",
            "Epoch 79/100\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 0.8212 - sparse_categorical_accuracy: 0.6762 - mean_absolute_error: 2.9742 - val_loss: 0.9141 - val_sparse_categorical_accuracy: 0.6466 - val_mean_absolute_error: 2.9625\n",
            "Epoch 80/100\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 0.8194 - sparse_categorical_accuracy: 0.6768 - mean_absolute_error: 2.9742 - val_loss: 0.9147 - val_sparse_categorical_accuracy: 0.6434 - val_mean_absolute_error: 2.9625\n",
            "Epoch 81/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.8195 - sparse_categorical_accuracy: 0.6745 - mean_absolute_error: 2.9742 - val_loss: 0.9174 - val_sparse_categorical_accuracy: 0.6403 - val_mean_absolute_error: 2.9625\n",
            "Epoch 82/100\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 0.8173 - sparse_categorical_accuracy: 0.6758 - mean_absolute_error: 2.9742 - val_loss: 0.9172 - val_sparse_categorical_accuracy: 0.6407 - val_mean_absolute_error: 2.9625\n",
            "Epoch 83/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.8161 - sparse_categorical_accuracy: 0.6763 - mean_absolute_error: 2.9742 - val_loss: 0.9155 - val_sparse_categorical_accuracy: 0.6431 - val_mean_absolute_error: 2.9625\n",
            "Epoch 84/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.8156 - sparse_categorical_accuracy: 0.6774 - mean_absolute_error: 2.9742 - val_loss: 0.9141 - val_sparse_categorical_accuracy: 0.6466 - val_mean_absolute_error: 2.9625\n",
            "Epoch 85/100\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 0.8156 - sparse_categorical_accuracy: 0.6780 - mean_absolute_error: 2.9742 - val_loss: 0.9178 - val_sparse_categorical_accuracy: 0.6419 - val_mean_absolute_error: 2.9625\n",
            "Epoch 86/100\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 0.8146 - sparse_categorical_accuracy: 0.6750 - mean_absolute_error: 2.9742 - val_loss: 0.9179 - val_sparse_categorical_accuracy: 0.6501 - val_mean_absolute_error: 2.9625\n",
            "Epoch 87/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.8128 - sparse_categorical_accuracy: 0.6772 - mean_absolute_error: 2.9742 - val_loss: 0.9145 - val_sparse_categorical_accuracy: 0.6438 - val_mean_absolute_error: 2.9625\n",
            "Epoch 88/100\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 0.8108 - sparse_categorical_accuracy: 0.6794 - mean_absolute_error: 2.9742 - val_loss: 0.9141 - val_sparse_categorical_accuracy: 0.6442 - val_mean_absolute_error: 2.9625\n",
            "Epoch 89/100\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 0.8109 - sparse_categorical_accuracy: 0.6828 - mean_absolute_error: 2.9742 - val_loss: 0.9296 - val_sparse_categorical_accuracy: 0.6411 - val_mean_absolute_error: 2.9625\n",
            "Epoch 90/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.8129 - sparse_categorical_accuracy: 0.6812 - mean_absolute_error: 2.9742 - val_loss: 0.9143 - val_sparse_categorical_accuracy: 0.6427 - val_mean_absolute_error: 2.9625\n",
            "Epoch 91/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.8090 - sparse_categorical_accuracy: 0.6807 - mean_absolute_error: 2.9742 - val_loss: 0.9151 - val_sparse_categorical_accuracy: 0.6431 - val_mean_absolute_error: 2.9625\n",
            "Epoch 92/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.8055 - sparse_categorical_accuracy: 0.6802 - mean_absolute_error: 2.9742 - val_loss: 0.9191 - val_sparse_categorical_accuracy: 0.6505 - val_mean_absolute_error: 2.9625\n",
            "Epoch 93/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.8052 - sparse_categorical_accuracy: 0.6812 - mean_absolute_error: 2.9742 - val_loss: 0.9188 - val_sparse_categorical_accuracy: 0.6442 - val_mean_absolute_error: 2.9625\n",
            "Epoch 94/100\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 0.8037 - sparse_categorical_accuracy: 0.6838 - mean_absolute_error: 2.9742 - val_loss: 0.9147 - val_sparse_categorical_accuracy: 0.6407 - val_mean_absolute_error: 2.9625\n",
            "Epoch 95/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.8041 - sparse_categorical_accuracy: 0.6794 - mean_absolute_error: 2.9742 - val_loss: 0.9135 - val_sparse_categorical_accuracy: 0.6442 - val_mean_absolute_error: 2.9625\n",
            "Epoch 96/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.8022 - sparse_categorical_accuracy: 0.6828 - mean_absolute_error: 2.9742 - val_loss: 0.9171 - val_sparse_categorical_accuracy: 0.6431 - val_mean_absolute_error: 2.9625\n",
            "Epoch 97/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.8029 - sparse_categorical_accuracy: 0.6849 - mean_absolute_error: 2.9742 - val_loss: 0.9138 - val_sparse_categorical_accuracy: 0.6415 - val_mean_absolute_error: 2.9625\n",
            "Epoch 98/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.8007 - sparse_categorical_accuracy: 0.6841 - mean_absolute_error: 2.9742 - val_loss: 0.9212 - val_sparse_categorical_accuracy: 0.6403 - val_mean_absolute_error: 2.9625\n",
            "Epoch 99/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.7975 - sparse_categorical_accuracy: 0.6851 - mean_absolute_error: 2.9742 - val_loss: 0.9196 - val_sparse_categorical_accuracy: 0.6423 - val_mean_absolute_error: 2.9625\n",
            "Epoch 100/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.7965 - sparse_categorical_accuracy: 0.6838 - mean_absolute_error: 2.9742 - val_loss: 0.9169 - val_sparse_categorical_accuracy: 0.6438 - val_mean_absolute_error: 2.9625\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_batch, \n",
        "                    epochs=100, \n",
        "                    validation_data=val_batch,\n",
        "                    callbacks=[tensorboard_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-62aa6fb896031d33\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-62aa6fb896031d33\");\n",
              "          const url = new URL(\"/\", window.location);\n",
              "          const port = 7;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#docs_infra: no_execute\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs2 --port=0007"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "01-Embedding_for_sentiment_analysis.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "5a55ff060dca2f919002028c6c65853c885111584988b328db325f9c1cd9b339"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
